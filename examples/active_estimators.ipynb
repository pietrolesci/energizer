{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from energizer.datastores import PandasDataStoreForSequenceClassification\n",
    "from energizer.estimators.estimator import Estimator\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from typing import Dict, List\n",
    "import torch\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.classification import Accuracy, F1Score, Precision, Recall\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from energizer.enums import InputKeys, OutputKeys, RunningStage\n",
    "import numpy as np\n",
    "from energizer.utilities import move_to_cpu\n",
    "from lightning.fabric.loggers import TensorBoardLogger\n",
    "from lightning.fabric import seed_everything\n",
    "from energizer.callbacks import GradNorm, PytorchTensorboardProfiler, EarlyStopping, ModelCheckpoint\n",
    "from energizer.strategies import RandomStrategy, UncertaintyBasedStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = PandasDataStoreForSequenceClassification.load(\"./agnews_datastore/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EstimatorForSequenceClassification(Estimator):\n",
    "\n",
    "    def train_step(self, model, batch, batch_idx, loss_fn, metrics: MetricCollection) -> Dict:\n",
    "        return self.step(model, batch, metrics, RunningStage.TRAIN)\n",
    "\n",
    "    def validation_step(self, model, batch, batch_idx, loss_fn, metrics: MetricCollection) -> Dict:\n",
    "        return self.step(model, batch, metrics, RunningStage.VALIDATION)\n",
    "\n",
    "    def test_step(self, model, batch, batch_idx, loss_fn, metrics: MetricCollection) -> Dict:\n",
    "        return self.step(model, batch, metrics, RunningStage.TEST)\n",
    "    \n",
    "    def train_epoch_end(self, output: List[np.ndarray], metrics: MetricCollection) -> Dict:\n",
    "        return self.epoch_end(output, metrics, RunningStage.TRAIN)\n",
    "\n",
    "    def validation_epoch_end(self, output: List[np.ndarray], metrics: MetricCollection) -> Dict:\n",
    "        return self.epoch_end(output, metrics, RunningStage.VALIDATION)\n",
    "\n",
    "    def test_epoch_end(self, output: List[np.ndarray], metrics: MetricCollection) -> Dict:\n",
    "        return self.epoch_end(output, metrics, RunningStage.TEST)\n",
    "\n",
    "    def step(self, model, batch: Dict, metrics: MetricCollection, stage: RunningStage) -> torch.Tensor:\n",
    "        _ = batch.pop(InputKeys.ON_CPU, None)\n",
    "\n",
    "        out = model(**batch)\n",
    "        out_metrics = metrics(out.logits, batch[InputKeys.TARGET])\n",
    "\n",
    "        if stage == RunningStage.TRAIN:\n",
    "            logs = {OutputKeys.LOSS: out.loss, **out_metrics}\n",
    "            self.log_dict({f\"{stage}/{k}\": v for k, v in logs.items()}, step=self.progress_tracker.global_batch)\n",
    "\n",
    "        return out.loss\n",
    "    \n",
    "    def epoch_end(self, output: List[np.ndarray], metrics: MetricCollection, stage: RunningStage) -> float:\n",
    "        aggregated_metrics = move_to_cpu(metrics.compute())  # NOTE: metrics are still on device\n",
    "        aggregated_loss = round(np.mean(output).item(), 6)\n",
    "        \n",
    "        logs = {OutputKeys.LOSS: aggregated_loss, **aggregated_metrics}\n",
    "        self.log_dict({f\"{stage}_end/{k}\": v for k, v in logs.items()}, step=self.progress_tracker.safe_global_epoch)\n",
    "\n",
    "        return aggregated_metrics\n",
    "\n",
    "    def configure_metrics(self, *_) -> MetricCollection:\n",
    "        num_classes = self.model.num_labels\n",
    "        task = \"multiclass\"\n",
    "        # NOTE: you are in charge of moving it to the correct device\n",
    "        return MetricCollection(\n",
    "            {\n",
    "                \"accuracy\": Accuracy(task, num_classes=num_classes),\n",
    "                \"f1_macro\": F1Score(task, num_classes=num_classes, average=\"macro\"),\n",
    "                \"precision_macro\": Precision(task, num_classes=num_classes, average=\"macro\"),\n",
    "                \"recall_macro\": Recall(task, num_classes=num_classes, average=\"macro\"),\n",
    "                \"f1_micro\": F1Score(task, num_classes=num_classes, average=\"micro\"),\n",
    "                \"precision_micro\": Precision(task, num_classes=num_classes, average=\"micro\"),\n",
    "                \"recall_micro\": Recall(task, num_classes=num_classes, average=\"micro\"),\n",
    "            }\n",
    "        ).to(self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Random strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomStrategyForSequenceClassification(EstimatorForSequenceClassification, RandomStrategy):\n",
    "    ...\n",
    "\n",
    "\n",
    "seed_everything(42)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    ds.tokenizer.name_or_path,\n",
    "    id2label=ds.id2label,\n",
    "    label2id=ds.label2id,\n",
    "    num_labels=len(ds.labels),\n",
    ")\n",
    "\n",
    "estimator = RandomStrategyForSequenceClassification(\n",
    "    model, \n",
    "    accelerator=\"gpu\", \n",
    "    loggers=[TensorBoardLogger(\"./\", name=\"tb_logs\")],\n",
    "    callbacks=[\n",
    "        GradNorm(2), \n",
    "        ModelCheckpoint(\"./checkpoints\", monitor=\"f1_macro\", stage=\"train\", mode=\"max\"),\n",
    "        EarlyStopping(monitor=\"f1_macro\", stage=\"train\", interval=\"epoch\", mode=\"max\"),\n",
    "    ],\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.prepare_for_loading()\n",
    "results = estimator.active_fit(\n",
    "    datastore=ds, \n",
    "    query_size=50,\n",
    "    max_rounds=20, \n",
    "    min_steps=50,\n",
    "    reinit_model=False,\n",
    "    # limit_pool_batches=10, \n",
    "    # limit_test_batches=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Entropy strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-2_H-128_A-2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "class UncertaintyBasedStrategyForSequenceClassification(EstimatorForSequenceClassification, UncertaintyBasedStrategy):\n",
    "    def pool_step( self, model, batch: Dict, batch_idx: int, metrics: MetricCollection) -> Dict:\n",
    "        _ = batch.pop(InputKeys.ON_CPU)  # this is already handled in the `evaluation_step`\n",
    "        logits = model(**batch).logits\n",
    "        return self.score_fn(logits)\n",
    "\n",
    "seed_everything(42)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    ds.tokenizer.name_or_path,\n",
    "    id2label=ds.id2label,\n",
    "    label2id=ds.label2id,\n",
    "    num_labels=len(ds.labels),\n",
    ")\n",
    "\n",
    "estimator = UncertaintyBasedStrategyForSequenceClassification(\n",
    "    score_fn=\"entropy\",\n",
    "    model=model, \n",
    "    accelerator=\"gpu\", \n",
    "    loggers=[TensorBoardLogger(\"./\", name=\"tb_logs\")],\n",
    "    callbacks=[\n",
    "        GradNorm(2), \n",
    "        ModelCheckpoint(\"./checkpoints\", monitor=\"f1_macro\", stage=\"train\", mode=\"max\"),\n",
    "        EarlyStopping(monitor=\"f1_macro\", stage=\"train\", interval=\"epoch\", mode=\"max\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42fed5d4bb46404088f070f9c9ebc822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completed rounds:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88f4df9b15e44ba892d55051dda4236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completed epochs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f92c9a383564b478a1771c55b0d3d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7beabc2f0404406ab2ee52daf6d4ebb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65f7a187e4f48e7a3d8c96f75444a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pool: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ds\u001b[39m.\u001b[39mprepare_for_loading()\n\u001b[0;32m----> 2\u001b[0m results \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39;49mactive_fit(\n\u001b[1;32m      3\u001b[0m     datastore\u001b[39m=\u001b[39;49mds, \n\u001b[1;32m      4\u001b[0m     query_size\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     max_rounds\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, \n\u001b[1;32m      6\u001b[0m     min_steps\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m )\n",
      "File \u001b[0;32m~/energizer/energizer/estimators/active_estimator.py:70\u001b[0m, in \u001b[0;36mActiveEstimator.active_fit\u001b[0;34m(self, datastore, query_size, validation_perc, max_rounds, max_budget, validation_sampling, reinit_model, max_epochs, min_steps, learning_rate, optimizer, optimizer_kwargs, scheduler, scheduler_kwargs, model_cache_dir, log_interval, enable_progress_bar, limit_train_batches, limit_validation_batches, limit_test_batches, limit_pool_batches, num_validation_per_epoch)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m# configure progress tracking\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress_tracker\u001b[39m.\u001b[39msetup(\n\u001b[1;32m     59\u001b[0m     max_rounds\u001b[39m=\u001b[39mmax_rounds,\n\u001b[1;32m     60\u001b[0m     max_budget\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(\u001b[39mmin\u001b[39m(datastore\u001b[39m.\u001b[39mpool_size(), max_budget \u001b[39mor\u001b[39;00m \u001b[39mfloat\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInf\u001b[39m\u001b[39m\"\u001b[39m))),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m     enable_progress_bar\u001b[39m=\u001b[39menable_progress_bar,\n\u001b[1;32m     68\u001b[0m )\n\u001b[0;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_active_fit(\n\u001b[1;32m     71\u001b[0m     datastore\u001b[39m=\u001b[39;49mdatastore,\n\u001b[1;32m     72\u001b[0m     replay\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     73\u001b[0m     reinit_model\u001b[39m=\u001b[39;49mreinit_model,\n\u001b[1;32m     74\u001b[0m     model_cache_dir\u001b[39m=\u001b[39;49mmodel_cache_dir,\n\u001b[1;32m     75\u001b[0m     max_epochs\u001b[39m=\u001b[39;49mmax_epochs,\n\u001b[1;32m     76\u001b[0m     min_steps\u001b[39m=\u001b[39;49mmin_steps,\n\u001b[1;32m     77\u001b[0m     learning_rate\u001b[39m=\u001b[39;49mlearning_rate,\n\u001b[1;32m     78\u001b[0m     optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m     79\u001b[0m     optimizer_kwargs\u001b[39m=\u001b[39;49moptimizer_kwargs,\n\u001b[1;32m     80\u001b[0m     scheduler\u001b[39m=\u001b[39;49mscheduler,\n\u001b[1;32m     81\u001b[0m     scheduler_kwargs\u001b[39m=\u001b[39;49mscheduler_kwargs,\n\u001b[1;32m     82\u001b[0m     query_size\u001b[39m=\u001b[39;49mquery_size,\n\u001b[1;32m     83\u001b[0m     validation_sampling\u001b[39m=\u001b[39;49mvalidation_sampling,\n\u001b[1;32m     84\u001b[0m     validation_perc\u001b[39m=\u001b[39;49mvalidation_perc,\n\u001b[1;32m     85\u001b[0m     limit_train_batches\u001b[39m=\u001b[39;49mlimit_train_batches,\n\u001b[1;32m     86\u001b[0m     limit_validation_batches\u001b[39m=\u001b[39;49mlimit_validation_batches,\n\u001b[1;32m     87\u001b[0m     limit_test_batches\u001b[39m=\u001b[39;49mlimit_test_batches,\n\u001b[1;32m     88\u001b[0m     limit_pool_batches\u001b[39m=\u001b[39;49mlimit_pool_batches,\n\u001b[1;32m     89\u001b[0m     num_validation_per_epoch\u001b[39m=\u001b[39;49mnum_validation_per_epoch,\n\u001b[1;32m     90\u001b[0m )\n",
      "File \u001b[0;32m~/energizer/energizer/estimators/active_estimator.py:115\u001b[0m, in \u001b[0;36mActiveEstimator.run_active_fit\u001b[0;34m(self, datastore, replay, reinit_model, model_cache_dir, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_state_dict(model_cache_dir)\n\u001b[1;32m    113\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfabric\u001b[39m.\u001b[39mcall(\u001b[39m\"\u001b[39m\u001b[39mon_round_start\u001b[39m\u001b[39m\"\u001b[39m, estimator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, datastore\u001b[39m=\u001b[39mdatastore)\n\u001b[0;32m--> 115\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_round(datastore\u001b[39m=\u001b[39;49mdatastore, replay\u001b[39m=\u001b[39;49mreplay, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    117\u001b[0m \u001b[39m# method to possibly aggregate\u001b[39;00m\n\u001b[1;32m    118\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mround_epoch_end(out, datastore)\n",
      "File \u001b[0;32m~/energizer/energizer/estimators/active_estimator.py:212\u001b[0m, in \u001b[0;36mActiveEstimator.run_round\u001b[0;34m(self, datastore, replay, max_epochs, min_steps, learning_rate, optimizer, optimizer_kwargs, scheduler, scheduler_kwargs, query_size, validation_perc, validation_sampling, num_validation_per_epoch, limit_train_batches, limit_validation_batches, limit_test_batches, limit_pool_batches)\u001b[0m\n\u001b[1;32m    206\u001b[0m n_labelled \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    208\u001b[0m     \u001b[39mnot\u001b[39;00m replay  \u001b[39m# do not annotate in replay\u001b[39;00m\n\u001b[1;32m    209\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress_tracker\u001b[39m.\u001b[39mis_last_round  \u001b[39m# last round is used only to test\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[39mand\u001b[39;00m datastore\u001b[39m.\u001b[39mpool_size(num_round) \u001b[39m>\u001b[39m query_size  \u001b[39m# enough instances\u001b[39;00m\n\u001b[1;32m    211\u001b[0m ):\n\u001b[0;32m--> 212\u001b[0m     n_labelled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_annotation(model, datastore, query_size, validation_perc, validation_sampling)\n\u001b[1;32m    213\u001b[0m \u001b[39melif\u001b[39;00m replay:\n\u001b[1;32m    214\u001b[0m     n_labelled \u001b[39m=\u001b[39m datastore\u001b[39m.\u001b[39mget_num_labelled_at_round(num_round)\n",
      "File \u001b[0;32m~/energizer/energizer/estimators/active_estimator.py:233\u001b[0m, in \u001b[0;36mActiveEstimator.run_annotation\u001b[0;34m(self, model, datastore, query_size, validation_perc, validation_sampling)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_annotation\u001b[39m(\n\u001b[1;32m    222\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    223\u001b[0m     model: _FabricModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m \n\u001b[1;32m    230\u001b[0m     \u001b[39m# query\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfabric\u001b[39m.\u001b[39mcall(\u001b[39m\"\u001b[39m\u001b[39mon_query_start\u001b[39m\u001b[39m\"\u001b[39m, estimator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, model\u001b[39m=\u001b[39mmodel)\n\u001b[0;32m--> 233\u001b[0m     indices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_query(model, datastore\u001b[39m=\u001b[39;49mdatastore, query_size\u001b[39m=\u001b[39;49mquery_size)\n\u001b[1;32m    235\u001b[0m     \u001b[39m# if with the current query we overrun the budget\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     remaining_budget \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress_tracker\u001b[39m.\u001b[39mbudget_tracker\u001b[39m.\u001b[39mget_remaining_budget()\n",
      "File \u001b[0;32m~/energizer/energizer/strategies/uncertainty.py:26\u001b[0m, in \u001b[0;36mUncertaintyBasedStrategy.run_query\u001b[0;34m(self, model, datastore, query_size)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_query\u001b[39m(\u001b[39mself\u001b[39m, model: _FabricModule, datastore: Datastore, query_size: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mint\u001b[39m]:\n\u001b[1;32m     25\u001b[0m     pool_loader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfigure_dataloader(datastore\u001b[39m.\u001b[39mpool_loader())\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_most_uncertain(model, pool_loader, query_size)\n",
      "File \u001b[0;32m~/energizer/energizer/strategies/uncertainty.py:33\u001b[0m, in \u001b[0;36mUncertaintyBasedStrategy.compute_most_uncertain\u001b[0;34m(self, model, pool_loader, query_size)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_most_uncertain\u001b[39m(\n\u001b[1;32m     29\u001b[0m     \u001b[39mself\u001b[39m, model: _FabricModule, pool_loader: _FabricDataLoader, query_size: \u001b[39mint\u001b[39m\n\u001b[1;32m     30\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mint\u001b[39m]:\n\u001b[1;32m     31\u001b[0m     \n\u001b[1;32m     32\u001b[0m     \u001b[39m# calls the pool_step and pool_epoch_end that we override\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     out: List[Dict] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_evaluation(model, pool_loader, RunningStage\u001b[39m.\u001b[39;49mPOOL)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     _out \u001b[39m=\u001b[39m ld_to_dl(out)\n\u001b[1;32m     35\u001b[0m     scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(_out[OutputKeys\u001b[39m.\u001b[39mSCORES])\n",
      "File \u001b[0;32m~/energizer/energizer/estimators/estimator.py:315\u001b[0m, in \u001b[0;36mEstimator.run_evaluation\u001b[0;34m(self, model, loader, stage)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39minference_mode():\n\u001b[1;32m    313\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress_tracker\u001b[39m.\u001b[39mis_done():\n\u001b[0;32m--> 315\u001b[0m         batch_idx, batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(iterable)\n\u001b[1;32m    317\u001b[0m         \u001b[39m# put batch on correct device\u001b[39;00m\n\u001b[1;32m    318\u001b[0m         batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransfer_to_device(batch)\n",
      "File \u001b[0;32m~/.conda/envs/energizer/lib/python3.9/site-packages/lightning/fabric/wrappers.py:217\u001b[0m, in \u001b[0;36m_FabricDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_iter_calls \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    216\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 217\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39miter\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataloader)\n\u001b[1;32m    218\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataloader:\n",
      "File \u001b[0;32m~/.conda/envs/energizer/lib/python3.9/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/energizer/lib/python3.9/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/energizer/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, \u001b[39m\"\u001b[39m\u001b[39m__getitems__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/energizer/lib/python3.9/site-packages/datasets/arrow_dataset.py:2782\u001b[0m, in \u001b[0;36mDataset.__getitems__\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m   2780\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitems__\u001b[39m(\u001b[39mself\u001b[39m, keys: List) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List:\n\u001b[1;32m   2781\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2782\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(keys)\n\u001b[1;32m   2783\u001b[0m     n_examples \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(batch[\u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(batch))])\n\u001b[1;32m   2784\u001b[0m     \u001b[39mreturn\u001b[39;00m [{col: array[i] \u001b[39mfor\u001b[39;00m col, array \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems()} \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_examples)]\n",
      "File \u001b[0;32m~/.conda/envs/energizer/lib/python3.9/site-packages/datasets/arrow_dataset.py:2778\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2776\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):  \u001b[39m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2777\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2778\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem(key)\n",
      "File \u001b[0;32m~/.conda/envs/energizer/lib/python3.9/site-packages/datasets/arrow_dataset.py:2762\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2760\u001b[0m format_kwargs \u001b[39m=\u001b[39m format_kwargs \u001b[39mif\u001b[39;00m format_kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m   2761\u001b[0m formatter \u001b[39m=\u001b[39m get_formatter(format_type, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info\u001b[39m.\u001b[39mfeatures, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mformat_kwargs)\n\u001b[0;32m-> 2762\u001b[0m pa_subtable \u001b[39m=\u001b[39m query_table(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data, key, indices\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_indices \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_indices \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   2763\u001b[0m formatted_output \u001b[39m=\u001b[39m format_table(\n\u001b[1;32m   2764\u001b[0m     pa_subtable, key, formatter\u001b[39m=\u001b[39mformatter, format_columns\u001b[39m=\u001b[39mformat_columns, output_all_columns\u001b[39m=\u001b[39moutput_all_columns\n\u001b[1;32m   2765\u001b[0m )\n\u001b[1;32m   2766\u001b[0m \u001b[39mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/.conda/envs/energizer/lib/python3.9/site-packages/datasets/formatting/formatting.py:581\u001b[0m, in \u001b[0;36mquery_table\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[39m# Query the main table\u001b[39;00m\n\u001b[1;32m    580\u001b[0m \u001b[39mif\u001b[39;00m indices \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 581\u001b[0m     pa_subtable \u001b[39m=\u001b[39m _query_table(table, key)\n\u001b[1;32m    582\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    583\u001b[0m     pa_subtable \u001b[39m=\u001b[39m _query_table_with_indices_mapping(table, key, indices\u001b[39m=\u001b[39mindices)\n",
      "File \u001b[0;32m~/.conda/envs/energizer/lib/python3.9/site-packages/datasets/formatting/formatting.py:100\u001b[0m, in \u001b[0;36m_query_table\u001b[0;34m(table, key)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39mtable\u001b[39m.\u001b[39mslice(\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[1;32m     99\u001b[0m     \u001b[39m# don't use pyarrow.Table.take even for pyarrow >=1.0 (see https://issues.apache.org/jira/browse/ARROW-9773)\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39;49mfast_gather(key \u001b[39m%\u001b[39;49m table\u001b[39m.\u001b[39;49mnum_rows)\n\u001b[1;32m    102\u001b[0m _raise_bad_key_type(key)\n",
      "File \u001b[0;32m~/.conda/envs/energizer/lib/python3.9/site-packages/datasets/table.py:120\u001b[0m, in \u001b[0;36mIndexedTableMixin.fast_gather\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIndices must be non-empty\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    118\u001b[0m batch_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msearchsorted(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offsets, indices, side\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mright\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39mTable\u001b[39m.\u001b[39mfrom_batches(\n\u001b[0;32m--> 120\u001b[0m     [\n\u001b[1;32m    121\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batches[batch_idx]\u001b[39m.\u001b[39mslice(i \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offsets[batch_idx], \u001b[39m1\u001b[39m)\n\u001b[1;32m    122\u001b[0m         \u001b[39mfor\u001b[39;00m batch_idx, i \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(batch_indices, indices)\n\u001b[1;32m    123\u001b[0m     ],\n\u001b[1;32m    124\u001b[0m     schema\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_schema,\n\u001b[1;32m    125\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/energizer/lib/python3.9/site-packages/datasets/table.py:121\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIndices must be non-empty\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    118\u001b[0m batch_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msearchsorted(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offsets, indices, side\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mright\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39mTable\u001b[39m.\u001b[39mfrom_batches(\n\u001b[1;32m    120\u001b[0m     [\n\u001b[0;32m--> 121\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batches[batch_idx]\u001b[39m.\u001b[39;49mslice(i \u001b[39m-\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_offsets[batch_idx], \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    122\u001b[0m         \u001b[39mfor\u001b[39;00m batch_idx, i \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(batch_indices, indices)\n\u001b[1;32m    123\u001b[0m     ],\n\u001b[1;32m    124\u001b[0m     schema\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_schema,\n\u001b[1;32m    125\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ds.prepare_for_loading()\n",
    "results = estimator.active_fit(\n",
    "    datastore=ds, \n",
    "    query_size=50,\n",
    "    max_rounds=20, \n",
    "    min_steps=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
