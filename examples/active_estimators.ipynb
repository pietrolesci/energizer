{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from energizer.datastores import PandasDataStoreForSequenceClassification\n",
    "from energizer.estimators.estimator import Estimator\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from typing import Dict, List\n",
    "import torch\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.classification import Accuracy, F1Score, Precision, Recall\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from energizer.enums import InputKeys, OutputKeys, RunningStage\n",
    "import numpy as np\n",
    "from energizer.utilities import move_to_cpu\n",
    "from lightning.fabric.loggers import TensorBoardLogger\n",
    "from lightning.fabric import seed_everything\n",
    "from energizer.callbacks import GradNorm, PytorchTensorboardProfiler\n",
    "from energizer.strategies import RandomStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = PandasDataStoreForSequenceClassification.load(\"./agnews_datastore/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActiveEstimatorForSequenceClassification(RandomStrategy):\n",
    "\n",
    "    def train_step(self, model, batch, batch_idx, loss_fn, metrics: MetricCollection) -> torch.Tensor:\n",
    "        return self.step(model, batch, metrics, RunningStage.TRAIN)\n",
    "\n",
    "    def validation_step(self, model, batch, batch_idx, loss_fn, metrics: MetricCollection) -> torch.Tensor:\n",
    "        return self.step(model, batch, metrics, RunningStage.VALIDATION)\n",
    "\n",
    "    def test_step(self, model, batch, batch_idx, loss_fn, metrics: MetricCollection) -> torch.Tensor:\n",
    "        return self.step(model, batch, metrics, RunningStage.TEST)\n",
    "    \n",
    "    def train_epoch_end(self, output: List[np.ndarray], metrics: MetricCollection) -> float:\n",
    "        return self.epoch_end(output, metrics, RunningStage.TRAIN)\n",
    "\n",
    "    def validation_epoch_end(self, output: List[np.ndarray], metrics: MetricCollection) -> float:\n",
    "        return self.epoch_end(output, metrics, RunningStage.VALIDATION)\n",
    "\n",
    "    def test_epoch_end(self, output: List[np.ndarray], metrics: MetricCollection) -> float:\n",
    "        return self.epoch_end(output, metrics, RunningStage.TEST)\n",
    "\n",
    "    def step(\n",
    "        self,\n",
    "        model,\n",
    "        batch: Dict,\n",
    "        metrics: MetricCollection,\n",
    "        stage: RunningStage,\n",
    "    ) -> torch.Tensor:\n",
    "        \n",
    "        _ = batch.pop(InputKeys.ON_CPU, None)\n",
    "\n",
    "        out = model(**batch)\n",
    "        out_metrics = metrics(out.logits, batch[InputKeys.TARGET])\n",
    "\n",
    "        if stage == RunningStage.TRAIN:\n",
    "            logs = {OutputKeys.LOSS: out.loss, **out_metrics}\n",
    "            self.log_dict({f\"{stage}/{k}\": v for k, v in logs.items()}, step=self.progress_tracker.global_batch)\n",
    "\n",
    "        return out.loss\n",
    "    \n",
    "    def epoch_end(self, output: List[np.ndarray], metrics: MetricCollection, stage: RunningStage) -> float:\n",
    "        aggregated_metrics = move_to_cpu(metrics.compute())  # NOTE: metrics are still on device\n",
    "        aggregated_loss = round(np.mean(output).item(), 6)\n",
    "        \n",
    "        logs = {OutputKeys.LOSS: aggregated_loss, **aggregated_metrics}\n",
    "        self.log_dict({f\"{stage}_end/{k}\": v for k, v in logs.items()}, step=self.progress_tracker.safe_global_epoch)\n",
    "\n",
    "        return aggregated_loss\n",
    "\n",
    "    def configure_metrics(self, *_) -> MetricCollection:\n",
    "        num_classes = self.model.num_labels\n",
    "        task = \"multiclass\"\n",
    "        # NOTE: you are in charge of moving it to the correct device\n",
    "        return MetricCollection(\n",
    "            {\n",
    "                \"accuracy\": Accuracy(task, num_classes=num_classes),\n",
    "                \"f1_macro\": F1Score(task, num_classes=num_classes, average=\"macro\"),\n",
    "                \"precision_macro\": Precision(task, num_classes=num_classes, average=\"macro\"),\n",
    "                \"recall_macro\": Recall(task, num_classes=num_classes, average=\"macro\"),\n",
    "                \"f1_micro\": F1Score(task, num_classes=num_classes, average=\"micro\"),\n",
    "                \"precision_micro\": Precision(task, num_classes=num_classes, average=\"micro\"),\n",
    "                \"recall_micro\": Recall(task, num_classes=num_classes, average=\"micro\"),\n",
    "            }\n",
    "        ).to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Some weights of the model checkpoint at google/bert_uncased_L-2_H-128_A-2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    ds.tokenizer.name_or_path,\n",
    "    id2label=ds.id2label,\n",
    "    label2id=ds.label2id,\n",
    "    num_labels=len(ds.labels),\n",
    ")\n",
    "\n",
    "estimator = ActiveEstimatorForSequenceClassification(\n",
    "    model, \n",
    "    accelerator=\"gpu\", \n",
    "    loggers=[TensorBoardLogger(\"./\")],\n",
    "    callbacks=[GradNorm(2), PytorchTensorboardProfiler(\"./profiler_logs\")],\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407c0e01ef754ad19f268ae892933719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completed rounds:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb21012ebb0546d98bf2fa0ae989b484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completed epochs: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d54ec8b8d84b3b943239cfe3b8c7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0c57ba4b09424fb0c5eae424bccbdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "250 == 150",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ds\u001b[39m.\u001b[39mprepare_for_loading()\n\u001b[0;32m----> 2\u001b[0m estimator\u001b[39m.\u001b[39;49mactive_fit(datastore\u001b[39m=\u001b[39;49mds, query_size\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, max_rounds\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, limit_pool_batches\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, limit_test_batches\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/energizer/energizer/estimators/active_estimator.py:70\u001b[0m, in \u001b[0;36mActiveEstimator.active_fit\u001b[0;34m(self, datastore, query_size, validation_perc, max_rounds, max_budget, validation_sampling, reinit_model, max_epochs, min_steps, learning_rate, optimizer, optimizer_kwargs, scheduler, scheduler_kwargs, model_cache_dir, log_interval, enable_progress_bar, limit_train_batches, limit_validation_batches, limit_test_batches, limit_pool_batches, num_validation_per_epoch)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39massert\u001b[39;00m max_budget \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m max_rounds \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     56\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mAt least one of `max_rounds` or `max_budget` must be not None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m )\n\u001b[1;32m     58\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress_tracker\u001b[39m.\u001b[39msetup(\n\u001b[1;32m     59\u001b[0m     max_rounds\u001b[39m=\u001b[39mmax_rounds \u001b[39mor\u001b[39;00m \u001b[39mfloat\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInf\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     60\u001b[0m     max_budget\u001b[39m=\u001b[39m\u001b[39mmin\u001b[39m(datastore\u001b[39m.\u001b[39mpool_size(), max_budget \u001b[39mor\u001b[39;00m \u001b[39mfloat\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInf\u001b[39m\u001b[39m\"\u001b[39m)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m     enable_progress_bar\u001b[39m=\u001b[39menable_progress_bar,\n\u001b[1;32m     68\u001b[0m )\n\u001b[0;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_active_fit(\n\u001b[1;32m     71\u001b[0m     replay\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     72\u001b[0m     datastore\u001b[39m=\u001b[39;49mdatastore,\n\u001b[1;32m     73\u001b[0m     max_epochs\u001b[39m=\u001b[39;49mmax_epochs,\n\u001b[1;32m     74\u001b[0m     min_steps\u001b[39m=\u001b[39;49mmin_steps,\n\u001b[1;32m     75\u001b[0m     learning_rate\u001b[39m=\u001b[39;49mlearning_rate,\n\u001b[1;32m     76\u001b[0m     optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m     77\u001b[0m     optimizer_kwargs\u001b[39m=\u001b[39;49moptimizer_kwargs,\n\u001b[1;32m     78\u001b[0m     scheduler\u001b[39m=\u001b[39;49mscheduler,\n\u001b[1;32m     79\u001b[0m     scheduler_kwargs\u001b[39m=\u001b[39;49mscheduler_kwargs,\n\u001b[1;32m     80\u001b[0m     reinit_model\u001b[39m=\u001b[39;49mreinit_model,\n\u001b[1;32m     81\u001b[0m     query_size\u001b[39m=\u001b[39;49mquery_size,\n\u001b[1;32m     82\u001b[0m     validation_sampling\u001b[39m=\u001b[39;49mvalidation_sampling,\n\u001b[1;32m     83\u001b[0m     validation_perc\u001b[39m=\u001b[39;49mvalidation_perc,\n\u001b[1;32m     84\u001b[0m     model_cache_dir\u001b[39m=\u001b[39;49mmodel_cache_dir,\n\u001b[1;32m     85\u001b[0m     limit_train_batches\u001b[39m=\u001b[39;49mlimit_train_batches,\n\u001b[1;32m     86\u001b[0m     limit_validation_batches\u001b[39m=\u001b[39;49mlimit_validation_batches,\n\u001b[1;32m     87\u001b[0m     limit_test_batches\u001b[39m=\u001b[39;49mlimit_test_batches,\n\u001b[1;32m     88\u001b[0m     limit_pool_batches\u001b[39m=\u001b[39;49mlimit_pool_batches,\n\u001b[1;32m     89\u001b[0m     num_validation_per_epoch\u001b[39m=\u001b[39;49mnum_validation_per_epoch,\n\u001b[1;32m     90\u001b[0m )\n",
      "File \u001b[0;32m~/energizer/energizer/estimators/active_estimator.py:211\u001b[0m, in \u001b[0;36mActiveEstimator.run_active_fit\u001b[0;34m(self, replay, datastore, max_epochs, min_steps, learning_rate, optimizer, optimizer_kwargs, scheduler, scheduler_kwargs, reinit_model, query_size, validation_sampling, validation_perc, model_cache_dir, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress_tracker\u001b[39m.\u001b[39mis_last_round:\n\u001b[1;32m    209\u001b[0m         \u001b[39m# print(self.progress_tracker.round_tracker)\u001b[39;00m\n\u001b[1;32m    210\u001b[0m         total_budget \u001b[39m=\u001b[39m datastore\u001b[39m.\u001b[39mlabelled_size(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress_tracker\u001b[39m.\u001b[39mglobal_round)\n\u001b[0;32m--> 211\u001b[0m         \u001b[39massert\u001b[39;00m (\n\u001b[1;32m    212\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress_tracker\u001b[39m.\u001b[39mbudget_tracker\u001b[39m.\u001b[39mcurrent \u001b[39m==\u001b[39m total_budget\n\u001b[1;32m    213\u001b[0m         ), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress_tracker\u001b[39m.\u001b[39mbudget_tracker\u001b[39m.\u001b[39mcurrent\u001b[39m}\u001b[39;00m\u001b[39m == \u001b[39m\u001b[39m{\u001b[39;00mtotal_budget\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactive_fit_end(output)\n\u001b[1;32m    217\u001b[0m \u001b[39m# call hook\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 250 == 150"
     ]
    }
   ],
   "source": [
    "ds.prepare_for_loading()\n",
    "estimator.active_fit(datastore=ds, query_size=50, max_rounds=3, limit_pool_batches=10, limit_test_batches=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
