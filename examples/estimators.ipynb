{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from energizer.datastores.classification import PandasDataStoreForSequenceClassification\n",
    "from energizer.estimator import Estimator\n",
    "from energizer.utilities import move_to_cpu\n",
    "from energizer.enums import InputKeys, OutputKeys, RunningStage\n",
    "from energizer import seed_everything\n",
    "from energizer.callbacks import GradNorm\n",
    "from energizer.active_learning.datastores.classification import ActivePandasDataStoreForSequenceClassification\n",
    "from typing import List, Dict\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.classification import Accuracy, F1Score, Precision, Recall\n",
    "from datasets import load_dataset\n",
    "from energizer.active_learning.strategies.random import RandomStrategy\n",
    "from energizer.active_learning.strategies.uncertainty import UncertaintyBasedStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = load_dataset(\"pietrolesci/agnews\")\n",
    "dataset_dict[\"train\"] = dataset_dict[\"train\"].select(range(1000))\n",
    "\n",
    "model_name = \"google/bert_uncased_L-2_H-128_A-2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "dataset_dict = dataset_dict.map(lambda ex: tokenizer(ex[\"text\"]), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function _from_datasets.<locals>.<lambda> at 0x7fb43fc123a0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2cb1e954064bc18d27247ad0e160ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118fd438327d4de6a67bee2f7653eed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = PandasDataStoreForSequenceClassification.from_dataset_dict(\n",
    "    dataset_dict=dataset_dict,\n",
    "    input_names=[\"input_ids\", \"attention_mask\"],\n",
    "    target_name=\"labels\",\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EstimatorForSequenceClassification(Estimator):\n",
    "\n",
    "    def step(\n",
    "        self,\n",
    "        stage: RunningStage,\n",
    "        model,\n",
    "        batch: Dict,\n",
    "        batch_idx: int,\n",
    "        loss_fn,\n",
    "        metrics: MetricCollection,\n",
    "    ) -> torch.Tensor:\n",
    "        \n",
    "        _ = batch.pop(InputKeys.ON_CPU, None)\n",
    "\n",
    "        out = model(**batch)\n",
    "        if stage == RunningStage.POOL:\n",
    "            return out.logits\n",
    "\n",
    "        out_metrics = metrics(out.logits, batch[InputKeys.TARGET])\n",
    "\n",
    "        if stage == RunningStage.TRAIN:\n",
    "            logs = {OutputKeys.LOSS: out.loss, **out_metrics}\n",
    "            self.log_dict({f\"{stage}/{k}\": v for k, v in logs.items()}, step=self.tracker.global_batch)\n",
    "\n",
    "        return out.loss\n",
    "    \n",
    "    def epoch_end(self, stage: RunningStage, output: List[np.ndarray], metrics: MetricCollection) -> float:\n",
    "        aggregated_metrics = move_to_cpu(metrics.compute())  # NOTE: metrics are still on device\n",
    "        aggregated_loss = round(np.mean(output).item(), 6)\n",
    "        \n",
    "        logs = {OutputKeys.LOSS: aggregated_loss, **aggregated_metrics}\n",
    "        self.log_dict({f\"{stage}_end/{k}\": v for k, v in logs.items()}, step=self.tracker.safe_global_epoch)\n",
    "\n",
    "        return aggregated_loss\n",
    "\n",
    "    def configure_metrics(self, *_) -> MetricCollection:\n",
    "        num_classes = self.model.num_labels\n",
    "        task = \"multiclass\"\n",
    "        # NOTE: you are in charge of moving it to the correct device\n",
    "        return MetricCollection(\n",
    "            {\n",
    "                \"accuracy\": Accuracy(task, num_classes=num_classes),\n",
    "                \"f1_macro\": F1Score(task, num_classes=num_classes, average=\"macro\"),\n",
    "                \"precision_macro\": Precision(task, num_classes=num_classes, average=\"macro\"),\n",
    "                \"recall_macro\": Recall(task, num_classes=num_classes, average=\"macro\"),\n",
    "                \"f1_micro\": F1Score(task, num_classes=num_classes, average=\"micro\"),\n",
    "                \"precision_micro\": Precision(task, num_classes=num_classes, average=\"micro\"),\n",
    "                \"recall_micro\": Recall(task, num_classes=num_classes, average=\"micro\"),\n",
    "            }\n",
    "        ).to(self.device)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "seed_everything(42)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    ds.tokenizer.name_or_path,\n",
    "    id2label=ds.id2label,\n",
    "    label2id=ds.label2id,\n",
    "    num_labels=len(ds.labels),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5989ea7e0e9349278cbe4ec1e5ae93dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimisation steps:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4396d3f4305240088f53290da63f4a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completed epochs:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89c5df2f2c34b10819aa6ffedeebbd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384d42d32555465bb2d13293a7ac1b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bf8c8d47d4412e841c771c8eaf2780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.370891"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.prepare_for_loading()\n",
    "\n",
    "estimator = EstimatorForSequenceClassification(\n",
    "    model, \n",
    "    accelerator=\"gpu\",\n",
    "    tf32_mode=\"high\",\n",
    "    # loggers=[TensorBoardLogger(\"./\")],\n",
    "    # callbacks=[GradNorm(2), PytorchTensorboardProfiler(\"./profiler_logs\")],\n",
    ")\n",
    "\n",
    "estimator.fit(\n",
    "    train_loader=ds.train_loader(),\n",
    "    validation_loader=ds.test_loader(),\n",
    "    validation_freq=\"1:step\",\n",
    "    limit_train_batches=5,\n",
    "    limit_validation_batches=1,\n",
    "    max_epochs=2,\n",
    "    learning_rate=0.001,\n",
    "    optimizer=\"adamw\",\n",
    "    gradient_accumulation_steps=2,\n",
    "    scheduler=\"cosine_schedule_with_warmup\",\n",
    "    scheduler_kwargs={\"num_warmup_steps\": .1},\n",
    ")\n",
    "\n",
    "estimator.test(loader=ds.test_loader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RandomStrategyForSequenceClassification(EstimatorForSequenceClassification, RandomStrategy):\n",
    "    ...\n",
    "\n",
    "class UncertaintyStrategy(EstimatorForSequenceClassification, UncertaintyBasedStrategy):\n",
    "    def pool_step(self, model, batch, batch_idx: int, metrics):\n",
    "        return super().step(RunningStage.POOL, model, batch, batch_idx, None, metrics)\n",
    "\n",
    "\n",
    "\n",
    "random = RandomStrategyForSequenceClassification(\n",
    "    model=model, accelerator=\"gpu\", tf32_mode=\"high\",\n",
    ")\n",
    "\n",
    "least_conf = UncertaintyStrategy(\n",
    "    model=model, accelerator=\"gpu\", tf32_mode=\"high\", score_fn=\"least_confidence\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd7593d82444890977df22ea4ca5919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimisation steps:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e93aabc0aacc47048961d5febacfa761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completed epochs:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd989610324649a08dccae5e7d576917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e767e57c13421ab88484514ad22374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377c488636fb41f29f67b6021576e4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfd8068616e49b6ad9c834385fdd3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimisation steps:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601c98305a2a4bfd957bd0023095c6af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completed epochs:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8394829791ee4ae48138d68ea5ce026a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6b0923139644a49f8b939d379b5f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e0251c698f4cf09adfa0ea8af2bcf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds.prepare_for_loading()\n",
    "\n",
    "for s in (random, least_conf):\n",
    "\n",
    "    s.fit(\n",
    "        train_loader=ds.train_loader(),\n",
    "        validation_loader=ds.test_loader(),\n",
    "        validation_freq=\"1:step\",\n",
    "        limit_train_batches=5,\n",
    "        limit_validation_batches=1,\n",
    "        max_epochs=2,\n",
    "        learning_rate=0.001,\n",
    "        optimizer=\"adamw\",\n",
    "        gradient_accumulation_steps=2,\n",
    "        scheduler=\"cosine_schedule_with_warmup\",\n",
    "        scheduler_kwargs={\"num_warmup_steps\": .1},\n",
    "    )\n",
    "\n",
    "    s.test(loader=ds.test_loader(), limit_batches=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads.labelled_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5be97ea20c4285b762fa83e922f161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7faf65e570aa4d9b990e5814d987e396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ads = ActivePandasDataStoreForSequenceClassification.from_dataset_dict(\n",
    "    dataset_dict=dataset_dict,\n",
    "    input_names=[\"input_ids\", \"attention_mask\"],\n",
    "    target_name=\"labels\",\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee96a8e273f4f1f9cd4bf29ff0e5912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completed rounds:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7309ffc7e21a4996b6ac1104faa3bf0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Labelled:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8eccc65858449f3b1cedbf3883f5a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimisation steps:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4903e9c5135b4cf9944813616f3d4694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completed epochs:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5bd179e8db4c7088896c57187e5d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 210:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1ec4fe7dba44d581066f79ca9d576d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "datastore_budget=15 and tracker_budget=75",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m ads\u001b[39m.\u001b[39mprepare_for_loading()\n\u001b[0;32m----> 3\u001b[0m random\u001b[39m.\u001b[39;49mactive_fit(\n\u001b[1;32m      4\u001b[0m     datastore\u001b[39m=\u001b[39;49mads,\n\u001b[1;32m      5\u001b[0m     validation_freq\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m1:step\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     limit_train_batches\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m     limit_validation_batches\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m     max_epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m     max_rounds\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m     learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m     optimizer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39madamw\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     12\u001b[0m     gradient_accumulation_steps\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m     13\u001b[0m     scheduler\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcosine_schedule_with_warmup\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     14\u001b[0m     scheduler_kwargs\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mnum_warmup_steps\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m.1\u001b[39;49m},\n\u001b[1;32m     15\u001b[0m     query_size\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m,\n\u001b[1;32m     16\u001b[0m     limit_test_batches\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m\n\u001b[1;32m     17\u001b[0m )\n",
      "File \u001b[0;32m~/anchoral/energizer/energizer/active_learning/strategies/base.py:74\u001b[0m, in \u001b[0;36mActiveEstimator.active_fit\u001b[0;34m(self, datastore, query_size, max_rounds, max_budget, validation_perc, validation_sampling, reinit_model, model_cache_dir, max_epochs, min_epochs, max_steps, min_steps, validation_freq, gradient_accumulation_steps, learning_rate, optimizer, optimizer_kwargs, scheduler, scheduler_kwargs, log_interval, enable_progress_bar, limit_train_batches, limit_validation_batches, limit_test_batches, limit_pool_batches)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39m# configure progress tracking\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtracker\u001b[39m.\u001b[39msetup_active(\n\u001b[1;32m     64\u001b[0m     log_interval\u001b[39m=\u001b[39mlog_interval,\n\u001b[1;32m     65\u001b[0m     enable_progress_bar\u001b[39m=\u001b[39menable_progress_bar,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     validation_perc\u001b[39m=\u001b[39mvalidation_perc,\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_active_fit(\n\u001b[1;32m     75\u001b[0m     datastore,\n\u001b[1;32m     76\u001b[0m     reinit_model,\n\u001b[1;32m     77\u001b[0m     model_cache_dir,\n\u001b[1;32m     78\u001b[0m     query_size\u001b[39m=\u001b[39;49mquery_size,\n\u001b[1;32m     79\u001b[0m     replay\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     80\u001b[0m     validation_sampling\u001b[39m=\u001b[39;49mvalidation_sampling,\n\u001b[1;32m     81\u001b[0m     validation_perc\u001b[39m=\u001b[39;49mvalidation_perc,\n\u001b[1;32m     82\u001b[0m     limit_test_batches\u001b[39m=\u001b[39;49mlimit_test_batches,\n\u001b[1;32m     83\u001b[0m     limit_pool_batches\u001b[39m=\u001b[39;49mlimit_pool_batches,\n\u001b[1;32m     84\u001b[0m     fit_loop_kwargs\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(\n\u001b[1;32m     85\u001b[0m         max_epochs\u001b[39m=\u001b[39;49mmax_epochs,\n\u001b[1;32m     86\u001b[0m         min_epochs\u001b[39m=\u001b[39;49mmin_epochs,\n\u001b[1;32m     87\u001b[0m         max_steps\u001b[39m=\u001b[39;49mmax_steps,\n\u001b[1;32m     88\u001b[0m         min_steps\u001b[39m=\u001b[39;49mmin_steps,\n\u001b[1;32m     89\u001b[0m         validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[1;32m     90\u001b[0m         gradient_accumulation_steps\u001b[39m=\u001b[39;49mgradient_accumulation_steps,\n\u001b[1;32m     91\u001b[0m         limit_train_batches\u001b[39m=\u001b[39;49mlimit_train_batches,\n\u001b[1;32m     92\u001b[0m         limit_validation_batches\u001b[39m=\u001b[39;49mlimit_validation_batches,\n\u001b[1;32m     93\u001b[0m     ),\n\u001b[1;32m     94\u001b[0m     fit_opt_kwargs\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(\n\u001b[1;32m     95\u001b[0m         learning_rate\u001b[39m=\u001b[39;49mlearning_rate,\n\u001b[1;32m     96\u001b[0m         optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m     97\u001b[0m         optimizer_kwargs\u001b[39m=\u001b[39;49moptimizer_kwargs,\n\u001b[1;32m     98\u001b[0m         scheduler\u001b[39m=\u001b[39;49mscheduler,\n\u001b[1;32m     99\u001b[0m         scheduler_kwargs\u001b[39m=\u001b[39;49mscheduler_kwargs,\n\u001b[1;32m    100\u001b[0m     ),\n\u001b[1;32m    101\u001b[0m )\n",
      "File \u001b[0;32m~/anchoral/energizer/energizer/active_learning/strategies/base.py:133\u001b[0m, in \u001b[0;36mActiveEstimator.run_active_fit\u001b[0;34m(self, datastore, reinit_model, model_cache_dir, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m         datastore_budget \u001b[39m=\u001b[39m datastore\u001b[39m.\u001b[39mlabelled_size(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtracker\u001b[39m.\u001b[39mglobal_round)\n\u001b[1;32m    132\u001b[0m         tracker_budget \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtracker\u001b[39m.\u001b[39mbudget_tracker\u001b[39m.\u001b[39mcurrent\n\u001b[0;32m--> 133\u001b[0m         \u001b[39massert\u001b[39;00m datastore_budget \u001b[39m==\u001b[39m tracker_budget, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdatastore_budget\u001b[39m=}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00mtracker_budget\u001b[39m=}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactive_fit_end(output)\n\u001b[1;32m    137\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback(\u001b[39m\"\u001b[39m\u001b[39mon_active_fit_end\u001b[39m\u001b[39m\"\u001b[39m, datastore\u001b[39m=\u001b[39mdatastore, output\u001b[39m=\u001b[39moutput)\n",
      "\u001b[0;31mAssertionError\u001b[0m: datastore_budget=15 and tracker_budget=75"
     ]
    }
   ],
   "source": [
    "ads.prepare_for_loading()\n",
    "\n",
    "random.active_fit(\n",
    "    datastore=ads,\n",
    "    validation_freq=\"1:step\",\n",
    "    limit_train_batches=5,\n",
    "    limit_validation_batches=1,\n",
    "    max_epochs=2,\n",
    "    max_rounds=5,\n",
    "    learning_rate=0.001,\n",
    "    optimizer=\"adamw\",\n",
    "    gradient_accumulation_steps=2,\n",
    "    scheduler=\"cosine_schedule_with_warmup\",\n",
    "    scheduler_kwargs={\"num_warmup_steps\": .1},\n",
    "    query_size=15,\n",
    "    limit_test_batches=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.tracker.global_budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BudgetTracker(current=15, max=880, query_size=15)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830dbc9589214a60bab9daedeafc416b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completed rounds:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de256ab7853b4928a137cb331e78e26c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Labelled:   0%|          | 0/880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1833c8a5832141a0aae1caa41303682b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimisation steps:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85344bbb2be940d1a883a8e67e4c8d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completed epochs:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9998e43192d4f23a607f6188b8df6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211152af6d0a40748246ad90d3836a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d8a91272364dd890cd71ac00c830f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pool: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "datastore_budget=30 and tracker_budget=15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m least_conf\u001b[39m.\u001b[39;49mactive_fit(\n\u001b[1;32m      2\u001b[0m     datastore\u001b[39m=\u001b[39;49mads,\n\u001b[1;32m      3\u001b[0m     validation_freq\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m1:step\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m     limit_train_batches\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     limit_validation_batches\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m     max_epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m      7\u001b[0m     max_rounds\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m     learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m     optimizer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39madamw\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m     gradient_accumulation_steps\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m     scheduler\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcosine_schedule_with_warmup\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     12\u001b[0m     scheduler_kwargs\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mnum_warmup_steps\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m.1\u001b[39;49m},\n\u001b[1;32m     13\u001b[0m     query_size\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m,\n\u001b[1;32m     14\u001b[0m     limit_test_batches\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m\n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m~/anchoral/energizer/energizer/active_learning/strategies/base.py:74\u001b[0m, in \u001b[0;36mActiveEstimator.active_fit\u001b[0;34m(self, datastore, query_size, max_rounds, max_budget, validation_perc, validation_sampling, reinit_model, model_cache_dir, max_epochs, min_epochs, max_steps, min_steps, validation_freq, gradient_accumulation_steps, learning_rate, optimizer, optimizer_kwargs, scheduler, scheduler_kwargs, log_interval, enable_progress_bar, limit_train_batches, limit_validation_batches, limit_test_batches, limit_pool_batches)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39m# configure progress tracking\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtracker\u001b[39m.\u001b[39msetup_active(\n\u001b[1;32m     64\u001b[0m     log_interval\u001b[39m=\u001b[39mlog_interval,\n\u001b[1;32m     65\u001b[0m     enable_progress_bar\u001b[39m=\u001b[39menable_progress_bar,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     validation_perc\u001b[39m=\u001b[39mvalidation_perc,\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_active_fit(\n\u001b[1;32m     75\u001b[0m     datastore,\n\u001b[1;32m     76\u001b[0m     reinit_model,\n\u001b[1;32m     77\u001b[0m     model_cache_dir,\n\u001b[1;32m     78\u001b[0m     query_size\u001b[39m=\u001b[39;49mquery_size,\n\u001b[1;32m     79\u001b[0m     replay\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     80\u001b[0m     validation_sampling\u001b[39m=\u001b[39;49mvalidation_sampling,\n\u001b[1;32m     81\u001b[0m     validation_perc\u001b[39m=\u001b[39;49mvalidation_perc,\n\u001b[1;32m     82\u001b[0m     limit_test_batches\u001b[39m=\u001b[39;49mlimit_test_batches,\n\u001b[1;32m     83\u001b[0m     limit_pool_batches\u001b[39m=\u001b[39;49mlimit_pool_batches,\n\u001b[1;32m     84\u001b[0m     fit_loop_kwargs\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(\n\u001b[1;32m     85\u001b[0m         max_epochs\u001b[39m=\u001b[39;49mmax_epochs,\n\u001b[1;32m     86\u001b[0m         min_epochs\u001b[39m=\u001b[39;49mmin_epochs,\n\u001b[1;32m     87\u001b[0m         max_steps\u001b[39m=\u001b[39;49mmax_steps,\n\u001b[1;32m     88\u001b[0m         min_steps\u001b[39m=\u001b[39;49mmin_steps,\n\u001b[1;32m     89\u001b[0m         validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[1;32m     90\u001b[0m         gradient_accumulation_steps\u001b[39m=\u001b[39;49mgradient_accumulation_steps,\n\u001b[1;32m     91\u001b[0m         limit_train_batches\u001b[39m=\u001b[39;49mlimit_train_batches,\n\u001b[1;32m     92\u001b[0m         limit_validation_batches\u001b[39m=\u001b[39;49mlimit_validation_batches,\n\u001b[1;32m     93\u001b[0m     ),\n\u001b[1;32m     94\u001b[0m     fit_opt_kwargs\u001b[39m=\u001b[39;49m\u001b[39mdict\u001b[39;49m(\n\u001b[1;32m     95\u001b[0m         learning_rate\u001b[39m=\u001b[39;49mlearning_rate,\n\u001b[1;32m     96\u001b[0m         optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m     97\u001b[0m         optimizer_kwargs\u001b[39m=\u001b[39;49moptimizer_kwargs,\n\u001b[1;32m     98\u001b[0m         scheduler\u001b[39m=\u001b[39;49mscheduler,\n\u001b[1;32m     99\u001b[0m         scheduler_kwargs\u001b[39m=\u001b[39;49mscheduler_kwargs,\n\u001b[1;32m    100\u001b[0m     ),\n\u001b[1;32m    101\u001b[0m )\n",
      "File \u001b[0;32m~/anchoral/energizer/energizer/active_learning/strategies/base.py:133\u001b[0m, in \u001b[0;36mActiveEstimator.run_active_fit\u001b[0;34m(self, datastore, reinit_model, model_cache_dir, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m         datastore_budget \u001b[39m=\u001b[39m datastore\u001b[39m.\u001b[39mlabelled_size(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtracker\u001b[39m.\u001b[39mglobal_round)\n\u001b[1;32m    132\u001b[0m         tracker_budget \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtracker\u001b[39m.\u001b[39mbudget_tracker\u001b[39m.\u001b[39mcurrent\n\u001b[0;32m--> 133\u001b[0m         \u001b[39massert\u001b[39;00m datastore_budget \u001b[39m==\u001b[39m tracker_budget, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdatastore_budget\u001b[39m=}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00mtracker_budget\u001b[39m=}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactive_fit_end(output)\n\u001b[1;32m    137\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback(\u001b[39m\"\u001b[39m\u001b[39mon_active_fit_end\u001b[39m\u001b[39m\"\u001b[39m, datastore\u001b[39m=\u001b[39mdatastore, output\u001b[39m=\u001b[39moutput)\n",
      "\u001b[0;31mAssertionError\u001b[0m: datastore_budget=30 and tracker_budget=15"
     ]
    }
   ],
   "source": [
    "\n",
    "least_conf.active_fit(\n",
    "    datastore=ads,\n",
    "    validation_freq=\"1:step\",\n",
    "    limit_train_batches=5,\n",
    "    limit_validation_batches=1,\n",
    "    max_epochs=2,\n",
    "    max_rounds=5,\n",
    "    learning_rate=0.001,\n",
    "    optimizer=\"adamw\",\n",
    "    gradient_accumulation_steps=2,\n",
    "    scheduler=\"cosine_schedule_with_warmup\",\n",
    "    scheduler_kwargs={\"num_warmup_steps\": .1},\n",
    "    query_size=15,\n",
    "    limit_test_batches=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least_conf.tracker.global_budget, least_conf.tracker.budget_tracker.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BudgetTracker(current=0, max=None, query_size=-1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least_conf.tracker.budget_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_conf.tracker.step_tracker.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
