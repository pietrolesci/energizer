{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Energizer is an Active-Learning framework for PyTorch based on PyTorch-Lightning Documentation: https://pietrolesci.github.io/energizer GitHub: https://github.com/pietrolesci/energizer PyPI: https://pypi.org/project/energizer/ Free software: MIT Features \u00b6 Energizer allows training any PyTorch-Lightning model using Active-Learning with no code changes, requiring minimal information from the user is modular and easily extensible by using the energizer primitives, in case you need the extra flexibility provides a unified and tidy interfaces for Active-Learning so that you can easily mix and match query strategies, acquisition functions, etc with no boilerplate code can easily scale to multi-node/multi-gpu settings thanks to the Pytorch-Lighting backend Gotchas and future plans \u00b6 At the moment energizer is focused on research settings. In other words, it works with datasets in which the labels are already available. Internally, it will mask the labels and mimick a true active learning setting. In the future, energizer will fully compatible with open-source annotation tools such as Label-Studio and Rubrix . Currently energizer has been extensively tested on cpu and single-node/single-gpu settings due to availability issues. Support for multi-node/multi-gpu settings should work out of the box thanks to Pytorch-Lightning but has not been tested at this stage. energizer supports pool-based active learning. We plan to add support for stream-based settings and for self-supervised training. Design \u00b6 A core principle of energizer is full compatibility with Pytorch-Lightning, that is with any LightningModule . By simply implementing the required hooks in the query strategy, it should be possible to actively train any LightningModule . The core objects in energizer are: The active learning loop: it is Pytorch-Lightning Loop that in essence implements the following steps at each labelling iteration 1 2 3 4 5 6 7 8 9 10 11 12 for _ in range ( max_labelling_epochs ): if labelled_data_available : # fit the model fit_loop . run () if can_run_testing : # if test_dataloader is provided test_loop . run () if unlabelled_data_available : indices = pool_loop . run () label_data ( indices ) Query strategy: it is a LightningModule itself that implements additional hooks and methods and is linked to a specific pool loop. The fundamental method of a query strategy is the query method which is in charge of returning the indices of the instances that needs to be labelled. To initialize a strategy, it is simply required to pass a LightningModule to the constructor 1 2 3 4 from energizer.query_strategies import RandomQueryStrategy model = MyGreatLightningModel () query_strategy = RandomQueryStrategy ( model ) Trainer: it provides a simple extension to the Pytorch-Lightning trainer by implementing the active_fit method (and other state-tracking properties). The trainer knows that when the active learning loop is either testing or fitting it will use the underlying LightningModule passed to the strategy, i.e. query_strategy.model in the example above. When it needs to run on the pool it will use the query_strategy directly. Pool loops: a pool loop is implemented using the Loop abstraction in Pytorch-Lightning. Pool loops control how the query strategies behave on the pool. For example, the RandomQueryStrategy that queries random instances from the pool does not need to run any computation on the pool. Other query strategies might need to run model inference on the pool and thus need to be treated separately. For this reason, a pool loop is tightly linked to a query strategy Usage \u00b6 The most basic usage of energizer requires minimal inputs from the user. Say we have the following LightningModule 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 class MNISTModel ( LightningModule ): def __init__ ( self ) -> None : super () . __init__ () self . model = nn . Sequential ( nn . Conv2d ( 1 , 32 , kernel_size = 5 ), nn . Dropout2d (), nn . MaxPool2d ( kernel_size = 2 ), nn . ReLU (), nn . Conv2d ( 32 , 64 , kernel_size = 5 ), nn . Dropout2d (), nn . MaxPool2d ( kernel_size = 2 ), nn . ReLU (), nn . Flatten (), nn . Linear ( 1024 , 128 ), nn . Dropout (), nn . Linear ( 128 , 10 ), ) def forward ( self , x : Union [ Tensor , Tuple [ Tensor , Tensor ]]) -> Tensor : \"\"\"NOTE: notice how we unpack the batch in forward method. More on this later. \"\"\" if isinstance ( x , tuple ): x , y = batch return self . model ( x ), y return self . model ( x ) def common_step ( self , batch : Tuple [ Tensor , Tensor ], stage : str ) -> Tensor : \"\"\"For convenience define a common step.\"\"\" logits , y = self ( batch ) loss = F . cross_entropy ( logits , y ) self . log ( f \" { stage } /loss\" , loss ) return loss def training_step ( self , batch : Tuple [ Tensor , Tensor ], batch_idx : int ) -> Tensor : return self . common_step ( batch , \"train\" ) def test_step ( self , batch : Tuple [ Tensor , Tensor ], batch_idx : int ) -> Tensor : return self . common_step ( batch , \"test\" ) def configure_optimizers ( self ) -> torch . optim . Optimizer : return torch . optim . SGD ( self . parameters (), lr = 0.001 ) model = MNISTModel () We need to select a query strategy, say the EntropyStrategy that queries instances from the pool for which the model is most uncertain. Uncertainty is defined as the entropy of the model predictive label distribution 1 2 3 from energizer.query_strategies import EntropyStrategy entropy_strategy = EntropyStrategy ( model ) NOTE : When a strategy is instantiated, internally it creates a deep copy of the model passed. This is to avoid sharing states if you want to try out different query strategies on the same model. This might change in the future! Now, to train the model with active learning we just need to apply the following changes 1 2 - from pytorch_lightning import Trainer + from energizer import Trainer And then call the active_fit method 1 2 3 4 5 6 7 8 9 10 11 12 trainer = Trainer ( max_labelling_epochs = 4 , # run the active learning loop 4 times query_size = 10 , # at each loop query 10 instances max_epochs = 3 , # fit the model on the labelled data for 3 epochs test_after_labelling = True , # test after each labelling # ... you can pass any other pl.Trainer arguments ) results = trainer . active_fit ( model = entropy_strategy , # ... dataloaders or datamodule ) The active_fit method will take care of masking the train dataloader and create a pool dataloader. And that's it! You will have a resulting model trained with active learning. The anatomy of a query strategy \u00b6 In the example abote, we used the EntropyStrategy . It needs to run model inference on the pool, get the logits, transform them into probabilities, and compute the entropy. So, contrarely to a RandomStrategy , we also need to implement how the model should behave when fed with a batch coming from the pool. In energizer we implement a base class called AccumulatorStrategy . The name comes from the fact that it accumulates the results of each batch and the returns the indices corresponding to the Top-K instances. Do not worry if you have a huge pool, it performs a running Top-K operation and keeps in memory only 2 * K instance at every time. In order to run pool-based active learning, we need to define how the model behaves when predicting on the unlabelled pool. This is achieved, by overriding the new \"pool\" hooks. An AccumulatorStrategy requires us to implement the pool_step method (similar to a training_step or test_step in Pytorch-Lightning) that runs inference on the batch and returns a 1-dimensional Tensor of scores (that are then Top-K-ed). So, if we were to implement the EntropyStrategy ourselves, we would simply do 1 2 3 4 5 6 from energizer.acquisition_functions import entropy class EntropyStrategy ( AccumulatorStrategy ): def pool_step ( self , batch : MODEL_INPUT , batch_idx : int , * args , ** kwargs ) -> Tensor : logits = self ( batch ) return entropy ( logits ) As simple as this. We do not need to implement the query method in this case because for AccumulatorStrategy s, the output of pool_step is continually aggregated and we simply need to perform an argmax operation to obtain the indices. This is handled directly by energizer . Note on research settings \u00b6 Finally, note that in our implementation of the EntropyStrategy the type of the batch input is MODEL_INPUT . This is to highlight that pool_step (by defaut, of course you can override it as you like) does not unpack a batch: it expectes that a batch can directly be passed to the forward of the underlying LightningModule . This is the case in real-world scenarios where you actually do not have a label. However, for research settings, we do have a label in each batch. Since energizer cannot know how to unpack a batch (it can be a dict , a tuple , your own custom data structure, etc) it also implements an additional hook that can be used for this purpose get_inputs_from_batch . So if you are in a research setting (your batch contains the labels and needs to be unpacked in order to extract the inputs), you have the following 3 options: Unpack a batch in the forward method of your LightningModule (as we did in the MNIST example) Define a forward method that expects only the inputs in your LightningModule (as it is usually done), subclass a query strategy (e.g, EntropyStrategy ), and implement the get_inputs_from_batch Define a forward method that expects only the inputs in your LightningModule (as it is usually done), subclass a query strategy (e.g, EntropyStrategy ), and implement the pool_step from scratch including the batch unpacking logic Contributing \u00b6 Install energizer locally 1 2 3 4 conda create -n energizer-dev python = 3 .9 -y # conda install poetry -y curl -sSL https://install.python-poetry.org | python3 - poetry install --all-extras --sync Credits \u00b6 This package was created with Cookiecutter and the waynerv/cookiecutter-pypackage project template.","title":"Home"},{"location":"#features","text":"Energizer allows training any PyTorch-Lightning model using Active-Learning with no code changes, requiring minimal information from the user is modular and easily extensible by using the energizer primitives, in case you need the extra flexibility provides a unified and tidy interfaces for Active-Learning so that you can easily mix and match query strategies, acquisition functions, etc with no boilerplate code can easily scale to multi-node/multi-gpu settings thanks to the Pytorch-Lighting backend","title":"Features"},{"location":"#gotchas-and-future-plans","text":"At the moment energizer is focused on research settings. In other words, it works with datasets in which the labels are already available. Internally, it will mask the labels and mimick a true active learning setting. In the future, energizer will fully compatible with open-source annotation tools such as Label-Studio and Rubrix . Currently energizer has been extensively tested on cpu and single-node/single-gpu settings due to availability issues. Support for multi-node/multi-gpu settings should work out of the box thanks to Pytorch-Lightning but has not been tested at this stage. energizer supports pool-based active learning. We plan to add support for stream-based settings and for self-supervised training.","title":"Gotchas and future plans"},{"location":"#design","text":"A core principle of energizer is full compatibility with Pytorch-Lightning, that is with any LightningModule . By simply implementing the required hooks in the query strategy, it should be possible to actively train any LightningModule . The core objects in energizer are: The active learning loop: it is Pytorch-Lightning Loop that in essence implements the following steps at each labelling iteration 1 2 3 4 5 6 7 8 9 10 11 12 for _ in range ( max_labelling_epochs ): if labelled_data_available : # fit the model fit_loop . run () if can_run_testing : # if test_dataloader is provided test_loop . run () if unlabelled_data_available : indices = pool_loop . run () label_data ( indices ) Query strategy: it is a LightningModule itself that implements additional hooks and methods and is linked to a specific pool loop. The fundamental method of a query strategy is the query method which is in charge of returning the indices of the instances that needs to be labelled. To initialize a strategy, it is simply required to pass a LightningModule to the constructor 1 2 3 4 from energizer.query_strategies import RandomQueryStrategy model = MyGreatLightningModel () query_strategy = RandomQueryStrategy ( model ) Trainer: it provides a simple extension to the Pytorch-Lightning trainer by implementing the active_fit method (and other state-tracking properties). The trainer knows that when the active learning loop is either testing or fitting it will use the underlying LightningModule passed to the strategy, i.e. query_strategy.model in the example above. When it needs to run on the pool it will use the query_strategy directly. Pool loops: a pool loop is implemented using the Loop abstraction in Pytorch-Lightning. Pool loops control how the query strategies behave on the pool. For example, the RandomQueryStrategy that queries random instances from the pool does not need to run any computation on the pool. Other query strategies might need to run model inference on the pool and thus need to be treated separately. For this reason, a pool loop is tightly linked to a query strategy","title":"Design"},{"location":"#usage","text":"The most basic usage of energizer requires minimal inputs from the user. Say we have the following LightningModule 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 class MNISTModel ( LightningModule ): def __init__ ( self ) -> None : super () . __init__ () self . model = nn . Sequential ( nn . Conv2d ( 1 , 32 , kernel_size = 5 ), nn . Dropout2d (), nn . MaxPool2d ( kernel_size = 2 ), nn . ReLU (), nn . Conv2d ( 32 , 64 , kernel_size = 5 ), nn . Dropout2d (), nn . MaxPool2d ( kernel_size = 2 ), nn . ReLU (), nn . Flatten (), nn . Linear ( 1024 , 128 ), nn . Dropout (), nn . Linear ( 128 , 10 ), ) def forward ( self , x : Union [ Tensor , Tuple [ Tensor , Tensor ]]) -> Tensor : \"\"\"NOTE: notice how we unpack the batch in forward method. More on this later. \"\"\" if isinstance ( x , tuple ): x , y = batch return self . model ( x ), y return self . model ( x ) def common_step ( self , batch : Tuple [ Tensor , Tensor ], stage : str ) -> Tensor : \"\"\"For convenience define a common step.\"\"\" logits , y = self ( batch ) loss = F . cross_entropy ( logits , y ) self . log ( f \" { stage } /loss\" , loss ) return loss def training_step ( self , batch : Tuple [ Tensor , Tensor ], batch_idx : int ) -> Tensor : return self . common_step ( batch , \"train\" ) def test_step ( self , batch : Tuple [ Tensor , Tensor ], batch_idx : int ) -> Tensor : return self . common_step ( batch , \"test\" ) def configure_optimizers ( self ) -> torch . optim . Optimizer : return torch . optim . SGD ( self . parameters (), lr = 0.001 ) model = MNISTModel () We need to select a query strategy, say the EntropyStrategy that queries instances from the pool for which the model is most uncertain. Uncertainty is defined as the entropy of the model predictive label distribution 1 2 3 from energizer.query_strategies import EntropyStrategy entropy_strategy = EntropyStrategy ( model ) NOTE : When a strategy is instantiated, internally it creates a deep copy of the model passed. This is to avoid sharing states if you want to try out different query strategies on the same model. This might change in the future! Now, to train the model with active learning we just need to apply the following changes 1 2 - from pytorch_lightning import Trainer + from energizer import Trainer And then call the active_fit method 1 2 3 4 5 6 7 8 9 10 11 12 trainer = Trainer ( max_labelling_epochs = 4 , # run the active learning loop 4 times query_size = 10 , # at each loop query 10 instances max_epochs = 3 , # fit the model on the labelled data for 3 epochs test_after_labelling = True , # test after each labelling # ... you can pass any other pl.Trainer arguments ) results = trainer . active_fit ( model = entropy_strategy , # ... dataloaders or datamodule ) The active_fit method will take care of masking the train dataloader and create a pool dataloader. And that's it! You will have a resulting model trained with active learning.","title":"Usage"},{"location":"#the-anatomy-of-a-query-strategy","text":"In the example abote, we used the EntropyStrategy . It needs to run model inference on the pool, get the logits, transform them into probabilities, and compute the entropy. So, contrarely to a RandomStrategy , we also need to implement how the model should behave when fed with a batch coming from the pool. In energizer we implement a base class called AccumulatorStrategy . The name comes from the fact that it accumulates the results of each batch and the returns the indices corresponding to the Top-K instances. Do not worry if you have a huge pool, it performs a running Top-K operation and keeps in memory only 2 * K instance at every time. In order to run pool-based active learning, we need to define how the model behaves when predicting on the unlabelled pool. This is achieved, by overriding the new \"pool\" hooks. An AccumulatorStrategy requires us to implement the pool_step method (similar to a training_step or test_step in Pytorch-Lightning) that runs inference on the batch and returns a 1-dimensional Tensor of scores (that are then Top-K-ed). So, if we were to implement the EntropyStrategy ourselves, we would simply do 1 2 3 4 5 6 from energizer.acquisition_functions import entropy class EntropyStrategy ( AccumulatorStrategy ): def pool_step ( self , batch : MODEL_INPUT , batch_idx : int , * args , ** kwargs ) -> Tensor : logits = self ( batch ) return entropy ( logits ) As simple as this. We do not need to implement the query method in this case because for AccumulatorStrategy s, the output of pool_step is continually aggregated and we simply need to perform an argmax operation to obtain the indices. This is handled directly by energizer .","title":"The anatomy of a query strategy"},{"location":"#note-on-research-settings","text":"Finally, note that in our implementation of the EntropyStrategy the type of the batch input is MODEL_INPUT . This is to highlight that pool_step (by defaut, of course you can override it as you like) does not unpack a batch: it expectes that a batch can directly be passed to the forward of the underlying LightningModule . This is the case in real-world scenarios where you actually do not have a label. However, for research settings, we do have a label in each batch. Since energizer cannot know how to unpack a batch (it can be a dict , a tuple , your own custom data structure, etc) it also implements an additional hook that can be used for this purpose get_inputs_from_batch . So if you are in a research setting (your batch contains the labels and needs to be unpacked in order to extract the inputs), you have the following 3 options: Unpack a batch in the forward method of your LightningModule (as we did in the MNIST example) Define a forward method that expects only the inputs in your LightningModule (as it is usually done), subclass a query strategy (e.g, EntropyStrategy ), and implement the get_inputs_from_batch Define a forward method that expects only the inputs in your LightningModule (as it is usually done), subclass a query strategy (e.g, EntropyStrategy ), and implement the pool_step from scratch including the batch unpacking logic","title":"Note on research settings"},{"location":"#contributing","text":"Install energizer locally 1 2 3 4 conda create -n energizer-dev python = 3 .9 -y # conda install poetry -y curl -sSL https://install.python-poetry.org | python3 - poetry install --all-extras --sync","title":"Contributing"},{"location":"#credits","text":"This package was created with Cookiecutter and the waynerv/cookiecutter-pypackage project template.","title":"Credits"},{"location":"about/","text":"","title":"About"},{"location":"changelog/","text":"Changelog \u00b6 0.1.0 (2021-12-17) \u00b6 First release on PyPI.","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#010-2021-12-17","text":"First release on PyPI.","title":"0.1.0 (2021-12-17)"},{"location":"contributing/","text":"Contributing \u00b6 Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways: Types of Contributions \u00b6 Report Bugs \u00b6 Report bugs at https://github.com/pietrolesci/pytorch-energizer/issues. If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug. Fix Bugs \u00b6 Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it. Implement Features \u00b6 Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it. Write Documentation \u00b6 Pytorch-Energizer could always use more documentation, whether as part of the official Pytorch-Energizer docs, in docstrings, or even on the web in blog posts, articles, and such. Submit Feedback \u00b6 The best way to send feedback is to file an issue at https://github.com/pietrolesci/pytorch-energizer/issues. If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :) Get Started! \u00b6 Ready to contribute? Here's how to set up pytorch-energizer for local development. Fork the pytorch-energizer repo on GitHub. Clone your fork locally 1 $ git clone git@github.com:your_name_here/pytorch-energizer.git Ensure poetry is installed. Install dependencies and start your virtualenv: 1 $ poetry install -E test -E doc -E dev Create a branch for local development: 1 $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass the tests, including testing other Python versions, with tox: 1 $ poetry run tox Commit your changes and push your branch to GitHub: 1 2 3 $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website. Pull Request Guidelines \u00b6 Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.6, 3.7, 3.8 and 3.9. Check https://github.com/pietrolesci/pytorch-energizer/actions and make sure that the tests pass for all supported Python versions. Tips \u00b6 1 $ poetry run pytest tests/test_energizer.py To run a subset of tests. Deploying \u00b6 A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in CHANGELOG.md). Then run: 1 2 3 $ poetry run bump2version patch # possible: major / minor / patch $ git push $ git push --tags GitHub Actions will then deploy to PyPI if tests pass.","title":"Contributing"},{"location":"contributing/#contributing","text":"Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways:","title":"Contributing"},{"location":"contributing/#types-of-contributions","text":"","title":"Types of Contributions"},{"location":"contributing/#report-bugs","text":"Report bugs at https://github.com/pietrolesci/pytorch-energizer/issues. If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug.","title":"Report Bugs"},{"location":"contributing/#fix-bugs","text":"Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.","title":"Fix Bugs"},{"location":"contributing/#implement-features","text":"Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.","title":"Implement Features"},{"location":"contributing/#write-documentation","text":"Pytorch-Energizer could always use more documentation, whether as part of the official Pytorch-Energizer docs, in docstrings, or even on the web in blog posts, articles, and such.","title":"Write Documentation"},{"location":"contributing/#submit-feedback","text":"The best way to send feedback is to file an issue at https://github.com/pietrolesci/pytorch-energizer/issues. If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :)","title":"Submit Feedback"},{"location":"contributing/#get-started","text":"Ready to contribute? Here's how to set up pytorch-energizer for local development. Fork the pytorch-energizer repo on GitHub. Clone your fork locally 1 $ git clone git@github.com:your_name_here/pytorch-energizer.git Ensure poetry is installed. Install dependencies and start your virtualenv: 1 $ poetry install -E test -E doc -E dev Create a branch for local development: 1 $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass the tests, including testing other Python versions, with tox: 1 $ poetry run tox Commit your changes and push your branch to GitHub: 1 2 3 $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website.","title":"Get Started!"},{"location":"contributing/#pull-request-guidelines","text":"Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.6, 3.7, 3.8 and 3.9. Check https://github.com/pietrolesci/pytorch-energizer/actions and make sure that the tests pass for all supported Python versions.","title":"Pull Request Guidelines"},{"location":"contributing/#tips","text":"1 $ poetry run pytest tests/test_energizer.py To run a subset of tests.","title":"Tips"},{"location":"contributing/#deploying","text":"A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in CHANGELOG.md). Then run: 1 2 3 $ poetry run bump2version patch # possible: major / minor / patch $ git push $ git push --tags GitHub Actions will then deploy to PyPI if tests pass.","title":"Deploying"},{"location":"installation/","text":"Installation \u00b6 Stable release \u00b6 To install Pytorch-Energizer, run this command in your terminal: 1 $ pip install pytorch-energizer This is the preferred method to install Pytorch-Energizer, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process. From source \u00b6 The source for Pytorch-Energizer can be downloaded from the Github repo . You can either clone the public repository: 1 $ git clone git://github.com/pietrolesci/pytorch-energizer Or download the tarball : 1 $ curl -OJL https://github.com/pietrolesci/pytorch-energizer/tarball/master Once you have a copy of the source, you can install it with: 1 $ pip install .","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#stable-release","text":"To install Pytorch-Energizer, run this command in your terminal: 1 $ pip install pytorch-energizer This is the preferred method to install Pytorch-Energizer, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process.","title":"Stable release"},{"location":"installation/#from-source","text":"The source for Pytorch-Energizer can be downloaded from the Github repo . You can either clone the public repository: 1 $ git clone git://github.com/pietrolesci/pytorch-energizer Or download the tarball : 1 $ curl -OJL https://github.com/pietrolesci/pytorch-energizer/tarball/master Once you have a copy of the source, you can install it with: 1 $ pip install .","title":"From source"},{"location":"api/acquisition_functions/","text":"bald ( logits ) \u00b6 Compute the BALD acquisition function. NOTE: this could have been simply implemented as 1 predictive_entropy ( logits ) - expected_entropy ( logits ) however, both functions would need to compute the softmax internally. To avoid doubling the computation uselessly, we implement this function so that it only computes the softmax ones. Source code in energizer/acquisition_functions.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 def bald ( logits : Tensor ) -> Tensor : r \"\"\"Compute the BALD acquisition function. NOTE: this could have been simply implemented as ```python predictive_entropy(logits) - expected_entropy(logits) ``` however, both functions would need to compute the softmax internally. To avoid doubling the computation uselessly, we implement this function so that it only computes the softmax ones. \"\"\" # predictive_entropy(logits) - expected_entropy(logits) probs = logits . softmax ( dim =- 2 ) # To get the first term, we make many runs, average the output, and measure the entropy. predictive_entropy = entr ( probs . mean ( dim =- 1 )) . sum ( dim =- 1 ) # To get the second term, we make many runs, measure the entropy of every run, and take the average. expected_entropy = entr ( probs ) . sum ( dim =- 2 ) . mean ( dim =- 1 ) return predictive_entropy - expected_entropy confidence ( logits , k = 1 ) \u00b6 Computes confidence based on logits. Computes the confidence defined as the highest probability the model assigns to a class, that is \\[\\max_c p_{bc}\\] where \\(p_{bc}\\) is the probability for class \\(c\\) for instance \\(b\\) in the batch. Parameters: Name Type Description Default logits Tensor A tensor of dimensions (B: batch_size, C: num_classes) . required k int The \"k\" in \"top-k\". 1 Returns: Type Description Tensor The confidence defined as the maximum probability assigned to a class, i.e. a vector of Tensor dimensions (B: batch_size, k) . Source code in energizer/acquisition_functions.py 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 def confidence ( logits : Tensor , k : int = 1 ) -> Tensor : r \"\"\"Computes confidence based on logits. Computes the confidence defined as the highest probability the model assigns to a class, that is $$\\max_c p_{bc}$$ where $p_{bc}$ is the probability for class $c$ for instance $b$ in the batch. Args: logits (Tensor): A tensor of dimensions `(B: batch_size, C: num_classes)`. k (int): The \"k\" in \"top-k\". Returns: The confidence defined as the maximum probability assigned to a class, i.e. a vector of dimensions `(B: batch_size, k)`. \"\"\" probs = logits . softmax ( dim =- 1 ) return torch . topk ( probs , k = k , sorted = True , dim =- 1 ) . values entropy ( logits ) \u00b6 Computes Shannon's entropy in nats. It expects a tensor of logits with the following dimensions: (B: batch_size, C: num_classes) . This function implements the following steps, for each element along the B: batch_size dimension: Converts logits in probabilities along the C: num_classes dimension \\( \\(p_{bc} = e^{l_{bc}} / \\sum_j e^{l_{bj}}\\) \\) Computes Shannon's entropy along the C: num_classes dimension \\( \\(\\mathrm{H}_b\\left(\\mathrm{p}(X)\\right) = - \\sum_c p_{bc} \\log(p_{bc})\\) \\) where \\(l_{bc}\\) is the logit for class \\(c\\) for the \\(b\\) -th element in the batch, and \\(\\mathrm{p}\\) is a probability mass function for a random variable \\(X\\) such that \\(\\mathrm{p}(X = c) = p_c\\) . Parameters: Name Type Description Default logits Tensor A tensor of dimensions (B: batch_size, C: num_classes) . required Returns: Type Description Tensor The Shannon's entropy, i.e. a vector of dimensions (B: batch_size,) . Source code in energizer/acquisition_functions.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def entropy ( logits : Tensor ) -> Tensor : r \"\"\"Computes Shannon's entropy in nats. It expects a tensor of logits with the following dimensions: `(B: batch_size, C: num_classes)`. This function implements the following steps, for each element along the `B: batch_size` dimension: - Converts logits in probabilities along the `C: num_classes` dimension $$p_{bc} = e^{l_{bc}} / \\sum_j e^{l_{bj}}$$ - Computes Shannon's entropy along the `C: num_classes` dimension $$\\mathrm{H}_b\\left(\\mathrm{p}(X)\\right) = - \\sum_c p_{bc} \\log(p_{bc})$$ where $l_{bc}$ is the logit for class $c$ for the $b$-th element in the batch, and $\\mathrm{p}$ is a probability mass function for a random variable $X$ such that $\\mathrm{p}(X = c) = p_c$. Args: logits (Tensor): A tensor of dimensions `(B: batch_size, C: num_classes)`. Returns: The Shannon's entropy, i.e. a vector of dimensions `(B: batch_size,)`. \"\"\" probs = logits . softmax ( dim =- 1 ) return entr ( probs ) . sum ( dim =- 1 ) # remember: you need to sum across classes expected_confidence ( logits , k = 1 ) \u00b6 Computes the expected confidence based on logits. Computes the expected confidence across samples, defined as the highest probability the model assigns to a class, that is \\[\\sum_s \\max_c p_{bcs}\\] where \\(p_{bcs}\\) is the probability for class \\(c\\) for instance \\(b\\) in batch of sample \\(s\\) . Parameters: Name Type Description Default logits Tensor A tensor of dimensions (B: batch_size, C: num_classes, S: num_samples) . required k int The \"k\" in \"top-k\". 1 Returns: Type Description Tensor The confidence defined as the maximum probability assigned to a class, i.e. a vector of Tensor dimensions (B: batch_size, k) . Source code in energizer/acquisition_functions.py 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 def expected_confidence ( logits : Tensor , k : int = 1 ) -> Tensor : r \"\"\"Computes the expected confidence based on logits. Computes the expected confidence across samples, defined as the highest probability the model assigns to a class, that is $$\\sum_s \\max_c p_{bcs}$$ where $p_{bcs}$ is the probability for class $c$ for instance $b$ in batch of sample $s$. Args: logits (Tensor): A tensor of dimensions `(B: batch_size, C: num_classes, S: num_samples)`. k (int): The \"k\" in \"top-k\". Returns: The confidence defined as the maximum probability assigned to a class, i.e. a vector of dimensions `(B: batch_size, k)`. \"\"\" probs = logits . softmax ( dim =- 2 ) confidence = torch . topk ( probs , k = k , sorted = True , dim =- 2 ) . values return confidence . mean ( dim =- 1 ) expected_entropy ( logits ) \u00b6 Computes the expected Shannon's entropy in nats. It expects a tensor of logits with the following dimensions: (B: batch_size, C: num_classes, S: num_inference_iterations) . This function implements the following steps, for each element along the B: batch_size dimension: Converts logits in probabilities along the C: num_classes dimension \\( \\(p_{bcs} = e^{l_{bcs}} / \\sum_j e^{l_{bjs}}\\) \\) Computes Shannon's entropy along the C: num_classes dimension \\( \\(\\mathrm{H}_{bs}\\left(\\mathrm{p}(X) \\right) = - \\sum_c p_{bcs} \\log(p_{bcs})\\) \\) Averages the Shannon's entropy along the S: num_samples dimension \\( \\(\\frac{1}{S} \\sum_s \\mathrm{H}_{bs}\\left(\\mathrm{p}(X)\\right)\\) \\) where \\(l_{bcs}\\) is the logit for class \\(c\\) for the \\(b\\) -th element in the batch in the \\(s\\) -th sample, and \\(\\mathrm{p}\\) is a probability mass function for a random variable \\(X\\) such that \\(\\mathrm{p}(X = c) = p_c\\) . Parameters: Name Type Description Default logits Tensor A tensor of dimensions (B: batch_size, C: num_classes, S: num_inference_iterations) . required Returns: Type Description Tensor The Shannon's entropy, i.e. a vector of dimensions (B: batch_size,) . Source code in energizer/acquisition_functions.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def expected_entropy ( logits : Tensor ) -> Tensor : r \"\"\"Computes the expected Shannon's entropy in nats. It expects a tensor of logits with the following dimensions: `(B: batch_size, C: num_classes, S: num_inference_iterations)`. This function implements the following steps, for each element along the `B: batch_size` dimension: - Converts logits in probabilities along the `C: num_classes` dimension $$p_{bcs} = e^{l_{bcs}} / \\sum_j e^{l_{bjs}}$$ - Computes Shannon's entropy along the `C: num_classes` dimension $$\\mathrm{H}_{bs}\\left(\\mathrm{p}(X) \\right) = - \\sum_c p_{bcs} \\log(p_{bcs})$$ - Averages the Shannon's entropy along the `S: num_samples` dimension $$\\frac{1}{S} \\sum_s \\mathrm{H}_{bs}\\left(\\mathrm{p}(X)\\right)$$ where $l_{bcs}$ is the logit for class $c$ for the $b$-th element in the batch in the $s$-th sample, and $\\mathrm{p}$ is a probability mass function for a random variable $X$ such that $\\mathrm{p}(X = c) = p_c$. Args: logits (Tensor): A tensor of dimensions `(B: batch_size, C: num_classes, S: num_inference_iterations)`. Returns: The Shannon's entropy, i.e. a vector of dimensions `(B: batch_size,)`. \"\"\" probs = logits . softmax ( dim =- 2 ) entropies = entr ( probs ) . sum ( dim =- 2 ) return entropies . mean ( dim =- 1 ) expected_least_confidence ( logits , k = 1 ) \u00b6 Implements the least confidence acquisition function. References: http://burrsettles.com/pub/settles.activelearning.pdf. This strategy allows an active learner to select the unlabeled data samples for which the model is least confident (i.e., most uncertain) in prediction or class assignment. It selects an instance \\(x\\) such that \\[\\arg \\max_{x} \\; 1 - p(y_{max}|x, \\theta)\\] where \\(y_{max} = \\arg\\max_y p(y|x, \\theta)\\) , i.e. the class label with the highest posterior probability under the model \\(\\theta\\) . One way to interpret this uncertainty measure is the expected 0/1-loss, i.e., the model's belief that it will mislabel \\(x\\) . If samples from a posterior distributions are provided, it computes \\[\\arg \\max_{x} \\; 1 - \\mathrm{E}_{p(\\theta| D)} p(y_{max}|x, \\theta)\\] Source code in energizer/acquisition_functions.py 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 def expected_least_confidence ( logits : Tensor , k : int = 1 ) -> Tensor : r \"\"\"Implements the least confidence acquisition function. References: http://burrsettles.com/pub/settles.activelearning.pdf. This strategy allows an active learner to select the unlabeled data samples for which the model is least confident (i.e., most uncertain) in prediction or class assignment. It selects an instance $x$ such that $$\\arg \\max_{x} \\; 1 - p(y_{max}|x, \\theta)$$ where $y_{max} = \\arg\\max_y p(y|x, \\theta)$, i.e. the class label with the highest posterior probability under the model $\\theta$. One way to interpret this uncertainty measure is the expected 0/1-loss, i.e., the model's belief that it will mislabel $x$. If samples from a posterior distributions are provided, it computes $$\\arg \\max_{x} \\; 1 - \\mathrm{E}_{p(\\theta| D)} p(y_{max}|x, \\theta)$$ \"\"\" return 1.0 - expected_confidence ( logits , k = k ) . flatten () expected_margin_confidence ( logits ) \u00b6 Implements the margin strategy. Reference: http://burrsettles.com/pub/settles.activelearning.pdf. Margin sampling aims to correct for a shortcoming in least confident strategy, by incorporating the posterior of the second most likely label. Intuitively, instances with large margins are easy, since the classifier has little doubt in differentiating between the two most likely class labels. Instances with small margins are more ambiguous, thus knowing the true label would help the model discriminate more effectively between them. It selects an instance \\(x\\) such that \\[\\arg\\min_{x} P(y_1|x, \\theta) - P(y_2|x, \\theta)\\] where \\(y_1\\) and \\(y_2\\) are the first and second most probable class labels under the model defined by \\(\\theta\\) , respectively. If samples from a posterior distributions are provided, it computes \\[\\arg\\min_{x} \\mathrm{E}_{p(\\theta| D)} P(y_1|x, \\theta) - \\mathrm{E}_{p(\\theta| D)} P(y_2|x, \\theta)\\] Source code in energizer/acquisition_functions.py 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 def expected_margin_confidence ( logits : Tensor ): r \"\"\"Implements the margin strategy. Reference: http://burrsettles.com/pub/settles.activelearning.pdf. Margin sampling aims to correct for a shortcoming in least confident strategy, by incorporating the posterior of the second most likely label. Intuitively, instances with large margins are easy, since the classifier has little doubt in differentiating between the two most likely class labels. Instances with small margins are more ambiguous, thus knowing the true label would help the model discriminate more effectively between them. It selects an instance $x$ such that $$\\arg\\min_{x} P(y_1|x, \\theta) - P(y_2|x, \\theta)$$ where $y_1$ and $y_2$ are the first and second most probable class labels under the model defined by $\\theta$, respectively. If samples from a posterior distributions are provided, it computes $$\\arg\\min_{x} \\mathrm{E}_{p(\\theta| D)} P(y_1|x, \\theta) - \\mathrm{E}_{p(\\theta| D)} P(y_2|x, \\theta)$$ \"\"\" confidence_top2 = expected_confidence ( logits , k = 2 ) return - ( confidence_top2 [:, 0 ] - confidence_top2 [:, 1 ]) . flatten () least_confidence ( logits ) \u00b6 Implements the least confidence acquisition function. References: http://burrsettles.com/pub/settles.activelearning.pdf. This strategy allows an active learner to select the unlabeled data samples for which the model is least confident (i.e., most uncertain) in prediction or class assignment. It selects an instance \\(x\\) such that \\[\\arg \\max_{x} \\; 1 - p(y_{max}|x, \\theta)\\] where \\(y_{max} = \\arg\\max_y p(y|x, \\theta)\\) , i.e. the class label with the highest posterior probability under the model \\(\\theta\\) . One way to interpret this uncertainty measure is the expected 0/1-loss, i.e., the model's belief that it will mislabel \\(x\\) . If samples from a posterior distributions are provided, it computes \\[\\arg \\max_{x} \\; 1 - \\mathrm{E}_{p(\\theta| D)} p(y_{max}|x, \\theta)\\] Source code in energizer/acquisition_functions.py 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 def least_confidence ( logits : Tensor ) -> Tensor : r \"\"\"Implements the least confidence acquisition function. References: http://burrsettles.com/pub/settles.activelearning.pdf. This strategy allows an active learner to select the unlabeled data samples for which the model is least confident (i.e., most uncertain) in prediction or class assignment. It selects an instance $x$ such that $$\\arg \\max_{x} \\; 1 - p(y_{max}|x, \\theta)$$ where $y_{max} = \\arg\\max_y p(y|x, \\theta)$, i.e. the class label with the highest posterior probability under the model $\\theta$. One way to interpret this uncertainty measure is the expected 0/1-loss, i.e., the model's belief that it will mislabel $x$. If samples from a posterior distributions are provided, it computes $$\\arg \\max_{x} \\; 1 - \\mathrm{E}_{p(\\theta| D)} p(y_{max}|x, \\theta)$$ \"\"\" return 1.0 - confidence ( logits , k = 1 ) . flatten () margin_confidence ( logits ) \u00b6 Implements the margin strategy. Reference: http://burrsettles.com/pub/settles.activelearning.pdf. Margin sampling aims to correct for a shortcoming in least confident strategy, by incorporating the posterior of the second most likely label. Intuitively, instances with large margins are easy, since the classifier has little doubt in differentiating between the two most likely class labels. Instances with small margins are more ambiguous, thus knowing the true label would help the model discriminate more effectively between them. It selects an instance \\(x\\) such that \\[\\arg\\min_{x} P(y_1|x, \\theta) - P(y_2|x, \\theta)\\] where \\(y_1\\) and \\(y_2\\) are the first and second most probable class labels under the model defined by \\(\\theta\\) , respectively. If samples from a posterior distributions are provided, it computes \\[\\arg\\min_{x} \\mathrm{E}_{p(\\theta| D)} P(y_1|x, \\theta) - \\mathrm{E}_{p(\\theta| D)} P(y_2|x, \\theta)\\] Source code in energizer/acquisition_functions.py 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 def margin_confidence ( logits : Tensor ) -> Tensor : r \"\"\"Implements the margin strategy. Reference: http://burrsettles.com/pub/settles.activelearning.pdf. Margin sampling aims to correct for a shortcoming in least confident strategy, by incorporating the posterior of the second most likely label. Intuitively, instances with large margins are easy, since the classifier has little doubt in differentiating between the two most likely class labels. Instances with small margins are more ambiguous, thus knowing the true label would help the model discriminate more effectively between them. It selects an instance $x$ such that $$\\arg\\min_{x} P(y_1|x, \\theta) - P(y_2|x, \\theta)$$ where $y_1$ and $y_2$ are the first and second most probable class labels under the model defined by $\\theta$, respectively. If samples from a posterior distributions are provided, it computes $$\\arg\\min_{x} \\mathrm{E}_{p(\\theta| D)} P(y_1|x, \\theta) - \\mathrm{E}_{p(\\theta| D)} P(y_2|x, \\theta)$$ \"\"\" confidence_top2 = confidence ( logits , k = 2 ) # we want the instances with the smallest gap, so we need to negate return - ( confidence_top2 [:, 0 ] - confidence_top2 [:, 1 ]) . flatten () predictive_entropy ( logits ) \u00b6 Computes the predictive Shannon's entropy in nats. It expects a tensor of logits with the following dimensions: (B: batch_size, C: num_classes, S: num_inference_iterations) . This function implements the following steps, for each element along the B: batch_size dimension: Converts logits in probabilities along the C: num_classes dimension \\( \\(p_{bcs} = e^{l_{bcs}} / \\sum_j e^{l_{bjs}}\\) \\) Averages the output probabilities per class across samples $$p_{bc} = \\frac{1}{S} \\sum_s p_{bcs} Computes Shannon's entropy along the C: num_classes dimension \\( \\(\\mathrm{H}_{b}\\left(\\mathrm{p}(X) \\right) = - \\sum_c p_{bc} \\log(p_{bc})\\) \\) where \\(l_{bcs}\\) is the logit for class \\(c\\) for the \\(b\\) -th element in the batch in the \\(s\\) -th sample, and \\(\\mathrm{p}\\) is a probability mass function for a random variable \\(X\\) such that \\(\\mathrm{p}(X = c) = p_c\\) . You can see the entropy function as a restriction of this in which we only have one sample. Parameters: Name Type Description Default logits Tensor A tensor of dimensions (B: batch_size, C: num_classes, S: num_inference_iterations) . required Returns: Type Description Tensor The Shannon's entropy, i.e. a vector of dimensions (B: batch_size,) . Source code in energizer/acquisition_functions.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 def predictive_entropy ( logits : Tensor ) -> Tensor : r \"\"\"Computes the predictive Shannon's entropy in nats. It expects a tensor of logits with the following dimensions: `(B: batch_size, C: num_classes, S: num_inference_iterations)`. This function implements the following steps, for each element along the `B: batch_size` dimension: - Converts logits in probabilities along the `C: num_classes` dimension $$p_{bcs} = e^{l_{bcs}} / \\sum_j e^{l_{bjs}}$$ - Averages the output probabilities per class across samples $$p_{bc} = \\frac{1}{S} \\sum_s p_{bcs} - Computes Shannon's entropy along the `C: num_classes` dimension $$\\mathrm{H}_{b}\\left(\\mathrm{p}(X) \\right) = - \\sum_c p_{bc} \\log(p_{bc})$$ where $l_{bcs}$ is the logit for class $c$ for the $b$-th element in the batch in the $s$-th sample, and $\\mathrm{p}$ is a probability mass function for a random variable $X$ such that $\\mathrm{p}(X = c) = p_c$. You can see the `entropy` function as a restriction of this in which we only have one sample. Args: logits (Tensor): A tensor of dimensions `(B: batch_size, C: num_classes, S: num_inference_iterations)`. Returns: The Shannon's entropy, i.e. a vector of dimensions `(B: batch_size,)`. \"\"\" avg_probs = logits . softmax ( dim =- 2 ) . mean ( dim =- 1 ) return entr ( avg_probs ) . sum ( dim =- 1 )","title":"Acquisition function"},{"location":"api/acquisition_functions/#energizer.acquisition_functions.bald","text":"Compute the BALD acquisition function. NOTE: this could have been simply implemented as 1 predictive_entropy ( logits ) - expected_entropy ( logits ) however, both functions would need to compute the softmax internally. To avoid doubling the computation uselessly, we implement this function so that it only computes the softmax ones. Source code in energizer/acquisition_functions.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 def bald ( logits : Tensor ) -> Tensor : r \"\"\"Compute the BALD acquisition function. NOTE: this could have been simply implemented as ```python predictive_entropy(logits) - expected_entropy(logits) ``` however, both functions would need to compute the softmax internally. To avoid doubling the computation uselessly, we implement this function so that it only computes the softmax ones. \"\"\" # predictive_entropy(logits) - expected_entropy(logits) probs = logits . softmax ( dim =- 2 ) # To get the first term, we make many runs, average the output, and measure the entropy. predictive_entropy = entr ( probs . mean ( dim =- 1 )) . sum ( dim =- 1 ) # To get the second term, we make many runs, measure the entropy of every run, and take the average. expected_entropy = entr ( probs ) . sum ( dim =- 2 ) . mean ( dim =- 1 ) return predictive_entropy - expected_entropy","title":"bald()"},{"location":"api/acquisition_functions/#energizer.acquisition_functions.confidence","text":"Computes confidence based on logits. Computes the confidence defined as the highest probability the model assigns to a class, that is \\[\\max_c p_{bc}\\] where \\(p_{bc}\\) is the probability for class \\(c\\) for instance \\(b\\) in the batch. Parameters: Name Type Description Default logits Tensor A tensor of dimensions (B: batch_size, C: num_classes) . required k int The \"k\" in \"top-k\". 1 Returns: Type Description Tensor The confidence defined as the maximum probability assigned to a class, i.e. a vector of Tensor dimensions (B: batch_size, k) . Source code in energizer/acquisition_functions.py 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 def confidence ( logits : Tensor , k : int = 1 ) -> Tensor : r \"\"\"Computes confidence based on logits. Computes the confidence defined as the highest probability the model assigns to a class, that is $$\\max_c p_{bc}$$ where $p_{bc}$ is the probability for class $c$ for instance $b$ in the batch. Args: logits (Tensor): A tensor of dimensions `(B: batch_size, C: num_classes)`. k (int): The \"k\" in \"top-k\". Returns: The confidence defined as the maximum probability assigned to a class, i.e. a vector of dimensions `(B: batch_size, k)`. \"\"\" probs = logits . softmax ( dim =- 1 ) return torch . topk ( probs , k = k , sorted = True , dim =- 1 ) . values","title":"confidence()"},{"location":"api/acquisition_functions/#energizer.acquisition_functions.entropy","text":"Computes Shannon's entropy in nats. It expects a tensor of logits with the following dimensions: (B: batch_size, C: num_classes) . This function implements the following steps, for each element along the B: batch_size dimension: Converts logits in probabilities along the C: num_classes dimension \\( \\(p_{bc} = e^{l_{bc}} / \\sum_j e^{l_{bj}}\\) \\) Computes Shannon's entropy along the C: num_classes dimension \\( \\(\\mathrm{H}_b\\left(\\mathrm{p}(X)\\right) = - \\sum_c p_{bc} \\log(p_{bc})\\) \\) where \\(l_{bc}\\) is the logit for class \\(c\\) for the \\(b\\) -th element in the batch, and \\(\\mathrm{p}\\) is a probability mass function for a random variable \\(X\\) such that \\(\\mathrm{p}(X = c) = p_c\\) . Parameters: Name Type Description Default logits Tensor A tensor of dimensions (B: batch_size, C: num_classes) . required Returns: Type Description Tensor The Shannon's entropy, i.e. a vector of dimensions (B: batch_size,) . Source code in energizer/acquisition_functions.py 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def entropy ( logits : Tensor ) -> Tensor : r \"\"\"Computes Shannon's entropy in nats. It expects a tensor of logits with the following dimensions: `(B: batch_size, C: num_classes)`. This function implements the following steps, for each element along the `B: batch_size` dimension: - Converts logits in probabilities along the `C: num_classes` dimension $$p_{bc} = e^{l_{bc}} / \\sum_j e^{l_{bj}}$$ - Computes Shannon's entropy along the `C: num_classes` dimension $$\\mathrm{H}_b\\left(\\mathrm{p}(X)\\right) = - \\sum_c p_{bc} \\log(p_{bc})$$ where $l_{bc}$ is the logit for class $c$ for the $b$-th element in the batch, and $\\mathrm{p}$ is a probability mass function for a random variable $X$ such that $\\mathrm{p}(X = c) = p_c$. Args: logits (Tensor): A tensor of dimensions `(B: batch_size, C: num_classes)`. Returns: The Shannon's entropy, i.e. a vector of dimensions `(B: batch_size,)`. \"\"\" probs = logits . softmax ( dim =- 1 ) return entr ( probs ) . sum ( dim =- 1 ) # remember: you need to sum across classes","title":"entropy()"},{"location":"api/acquisition_functions/#energizer.acquisition_functions.expected_confidence","text":"Computes the expected confidence based on logits. Computes the expected confidence across samples, defined as the highest probability the model assigns to a class, that is \\[\\sum_s \\max_c p_{bcs}\\] where \\(p_{bcs}\\) is the probability for class \\(c\\) for instance \\(b\\) in batch of sample \\(s\\) . Parameters: Name Type Description Default logits Tensor A tensor of dimensions (B: batch_size, C: num_classes, S: num_samples) . required k int The \"k\" in \"top-k\". 1 Returns: Type Description Tensor The confidence defined as the maximum probability assigned to a class, i.e. a vector of Tensor dimensions (B: batch_size, k) . Source code in energizer/acquisition_functions.py 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 def expected_confidence ( logits : Tensor , k : int = 1 ) -> Tensor : r \"\"\"Computes the expected confidence based on logits. Computes the expected confidence across samples, defined as the highest probability the model assigns to a class, that is $$\\sum_s \\max_c p_{bcs}$$ where $p_{bcs}$ is the probability for class $c$ for instance $b$ in batch of sample $s$. Args: logits (Tensor): A tensor of dimensions `(B: batch_size, C: num_classes, S: num_samples)`. k (int): The \"k\" in \"top-k\". Returns: The confidence defined as the maximum probability assigned to a class, i.e. a vector of dimensions `(B: batch_size, k)`. \"\"\" probs = logits . softmax ( dim =- 2 ) confidence = torch . topk ( probs , k = k , sorted = True , dim =- 2 ) . values return confidence . mean ( dim =- 1 )","title":"expected_confidence()"},{"location":"api/acquisition_functions/#energizer.acquisition_functions.expected_entropy","text":"Computes the expected Shannon's entropy in nats. It expects a tensor of logits with the following dimensions: (B: batch_size, C: num_classes, S: num_inference_iterations) . This function implements the following steps, for each element along the B: batch_size dimension: Converts logits in probabilities along the C: num_classes dimension \\( \\(p_{bcs} = e^{l_{bcs}} / \\sum_j e^{l_{bjs}}\\) \\) Computes Shannon's entropy along the C: num_classes dimension \\( \\(\\mathrm{H}_{bs}\\left(\\mathrm{p}(X) \\right) = - \\sum_c p_{bcs} \\log(p_{bcs})\\) \\) Averages the Shannon's entropy along the S: num_samples dimension \\( \\(\\frac{1}{S} \\sum_s \\mathrm{H}_{bs}\\left(\\mathrm{p}(X)\\right)\\) \\) where \\(l_{bcs}\\) is the logit for class \\(c\\) for the \\(b\\) -th element in the batch in the \\(s\\) -th sample, and \\(\\mathrm{p}\\) is a probability mass function for a random variable \\(X\\) such that \\(\\mathrm{p}(X = c) = p_c\\) . Parameters: Name Type Description Default logits Tensor A tensor of dimensions (B: batch_size, C: num_classes, S: num_inference_iterations) . required Returns: Type Description Tensor The Shannon's entropy, i.e. a vector of dimensions (B: batch_size,) . Source code in energizer/acquisition_functions.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def expected_entropy ( logits : Tensor ) -> Tensor : r \"\"\"Computes the expected Shannon's entropy in nats. It expects a tensor of logits with the following dimensions: `(B: batch_size, C: num_classes, S: num_inference_iterations)`. This function implements the following steps, for each element along the `B: batch_size` dimension: - Converts logits in probabilities along the `C: num_classes` dimension $$p_{bcs} = e^{l_{bcs}} / \\sum_j e^{l_{bjs}}$$ - Computes Shannon's entropy along the `C: num_classes` dimension $$\\mathrm{H}_{bs}\\left(\\mathrm{p}(X) \\right) = - \\sum_c p_{bcs} \\log(p_{bcs})$$ - Averages the Shannon's entropy along the `S: num_samples` dimension $$\\frac{1}{S} \\sum_s \\mathrm{H}_{bs}\\left(\\mathrm{p}(X)\\right)$$ where $l_{bcs}$ is the logit for class $c$ for the $b$-th element in the batch in the $s$-th sample, and $\\mathrm{p}$ is a probability mass function for a random variable $X$ such that $\\mathrm{p}(X = c) = p_c$. Args: logits (Tensor): A tensor of dimensions `(B: batch_size, C: num_classes, S: num_inference_iterations)`. Returns: The Shannon's entropy, i.e. a vector of dimensions `(B: batch_size,)`. \"\"\" probs = logits . softmax ( dim =- 2 ) entropies = entr ( probs ) . sum ( dim =- 2 ) return entropies . mean ( dim =- 1 )","title":"expected_entropy()"},{"location":"api/acquisition_functions/#energizer.acquisition_functions.expected_least_confidence","text":"Implements the least confidence acquisition function. References: http://burrsettles.com/pub/settles.activelearning.pdf. This strategy allows an active learner to select the unlabeled data samples for which the model is least confident (i.e., most uncertain) in prediction or class assignment. It selects an instance \\(x\\) such that \\[\\arg \\max_{x} \\; 1 - p(y_{max}|x, \\theta)\\] where \\(y_{max} = \\arg\\max_y p(y|x, \\theta)\\) , i.e. the class label with the highest posterior probability under the model \\(\\theta\\) . One way to interpret this uncertainty measure is the expected 0/1-loss, i.e., the model's belief that it will mislabel \\(x\\) . If samples from a posterior distributions are provided, it computes \\[\\arg \\max_{x} \\; 1 - \\mathrm{E}_{p(\\theta| D)} p(y_{max}|x, \\theta)\\] Source code in energizer/acquisition_functions.py 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 def expected_least_confidence ( logits : Tensor , k : int = 1 ) -> Tensor : r \"\"\"Implements the least confidence acquisition function. References: http://burrsettles.com/pub/settles.activelearning.pdf. This strategy allows an active learner to select the unlabeled data samples for which the model is least confident (i.e., most uncertain) in prediction or class assignment. It selects an instance $x$ such that $$\\arg \\max_{x} \\; 1 - p(y_{max}|x, \\theta)$$ where $y_{max} = \\arg\\max_y p(y|x, \\theta)$, i.e. the class label with the highest posterior probability under the model $\\theta$. One way to interpret this uncertainty measure is the expected 0/1-loss, i.e., the model's belief that it will mislabel $x$. If samples from a posterior distributions are provided, it computes $$\\arg \\max_{x} \\; 1 - \\mathrm{E}_{p(\\theta| D)} p(y_{max}|x, \\theta)$$ \"\"\" return 1.0 - expected_confidence ( logits , k = k ) . flatten ()","title":"expected_least_confidence()"},{"location":"api/acquisition_functions/#energizer.acquisition_functions.expected_margin_confidence","text":"Implements the margin strategy. Reference: http://burrsettles.com/pub/settles.activelearning.pdf. Margin sampling aims to correct for a shortcoming in least confident strategy, by incorporating the posterior of the second most likely label. Intuitively, instances with large margins are easy, since the classifier has little doubt in differentiating between the two most likely class labels. Instances with small margins are more ambiguous, thus knowing the true label would help the model discriminate more effectively between them. It selects an instance \\(x\\) such that \\[\\arg\\min_{x} P(y_1|x, \\theta) - P(y_2|x, \\theta)\\] where \\(y_1\\) and \\(y_2\\) are the first and second most probable class labels under the model defined by \\(\\theta\\) , respectively. If samples from a posterior distributions are provided, it computes \\[\\arg\\min_{x} \\mathrm{E}_{p(\\theta| D)} P(y_1|x, \\theta) - \\mathrm{E}_{p(\\theta| D)} P(y_2|x, \\theta)\\] Source code in energizer/acquisition_functions.py 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 def expected_margin_confidence ( logits : Tensor ): r \"\"\"Implements the margin strategy. Reference: http://burrsettles.com/pub/settles.activelearning.pdf. Margin sampling aims to correct for a shortcoming in least confident strategy, by incorporating the posterior of the second most likely label. Intuitively, instances with large margins are easy, since the classifier has little doubt in differentiating between the two most likely class labels. Instances with small margins are more ambiguous, thus knowing the true label would help the model discriminate more effectively between them. It selects an instance $x$ such that $$\\arg\\min_{x} P(y_1|x, \\theta) - P(y_2|x, \\theta)$$ where $y_1$ and $y_2$ are the first and second most probable class labels under the model defined by $\\theta$, respectively. If samples from a posterior distributions are provided, it computes $$\\arg\\min_{x} \\mathrm{E}_{p(\\theta| D)} P(y_1|x, \\theta) - \\mathrm{E}_{p(\\theta| D)} P(y_2|x, \\theta)$$ \"\"\" confidence_top2 = expected_confidence ( logits , k = 2 ) return - ( confidence_top2 [:, 0 ] - confidence_top2 [:, 1 ]) . flatten ()","title":"expected_margin_confidence()"},{"location":"api/acquisition_functions/#energizer.acquisition_functions.least_confidence","text":"Implements the least confidence acquisition function. References: http://burrsettles.com/pub/settles.activelearning.pdf. This strategy allows an active learner to select the unlabeled data samples for which the model is least confident (i.e., most uncertain) in prediction or class assignment. It selects an instance \\(x\\) such that \\[\\arg \\max_{x} \\; 1 - p(y_{max}|x, \\theta)\\] where \\(y_{max} = \\arg\\max_y p(y|x, \\theta)\\) , i.e. the class label with the highest posterior probability under the model \\(\\theta\\) . One way to interpret this uncertainty measure is the expected 0/1-loss, i.e., the model's belief that it will mislabel \\(x\\) . If samples from a posterior distributions are provided, it computes \\[\\arg \\max_{x} \\; 1 - \\mathrm{E}_{p(\\theta| D)} p(y_{max}|x, \\theta)\\] Source code in energizer/acquisition_functions.py 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 def least_confidence ( logits : Tensor ) -> Tensor : r \"\"\"Implements the least confidence acquisition function. References: http://burrsettles.com/pub/settles.activelearning.pdf. This strategy allows an active learner to select the unlabeled data samples for which the model is least confident (i.e., most uncertain) in prediction or class assignment. It selects an instance $x$ such that $$\\arg \\max_{x} \\; 1 - p(y_{max}|x, \\theta)$$ where $y_{max} = \\arg\\max_y p(y|x, \\theta)$, i.e. the class label with the highest posterior probability under the model $\\theta$. One way to interpret this uncertainty measure is the expected 0/1-loss, i.e., the model's belief that it will mislabel $x$. If samples from a posterior distributions are provided, it computes $$\\arg \\max_{x} \\; 1 - \\mathrm{E}_{p(\\theta| D)} p(y_{max}|x, \\theta)$$ \"\"\" return 1.0 - confidence ( logits , k = 1 ) . flatten ()","title":"least_confidence()"},{"location":"api/acquisition_functions/#energizer.acquisition_functions.margin_confidence","text":"Implements the margin strategy. Reference: http://burrsettles.com/pub/settles.activelearning.pdf. Margin sampling aims to correct for a shortcoming in least confident strategy, by incorporating the posterior of the second most likely label. Intuitively, instances with large margins are easy, since the classifier has little doubt in differentiating between the two most likely class labels. Instances with small margins are more ambiguous, thus knowing the true label would help the model discriminate more effectively between them. It selects an instance \\(x\\) such that \\[\\arg\\min_{x} P(y_1|x, \\theta) - P(y_2|x, \\theta)\\] where \\(y_1\\) and \\(y_2\\) are the first and second most probable class labels under the model defined by \\(\\theta\\) , respectively. If samples from a posterior distributions are provided, it computes \\[\\arg\\min_{x} \\mathrm{E}_{p(\\theta| D)} P(y_1|x, \\theta) - \\mathrm{E}_{p(\\theta| D)} P(y_2|x, \\theta)\\] Source code in energizer/acquisition_functions.py 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 def margin_confidence ( logits : Tensor ) -> Tensor : r \"\"\"Implements the margin strategy. Reference: http://burrsettles.com/pub/settles.activelearning.pdf. Margin sampling aims to correct for a shortcoming in least confident strategy, by incorporating the posterior of the second most likely label. Intuitively, instances with large margins are easy, since the classifier has little doubt in differentiating between the two most likely class labels. Instances with small margins are more ambiguous, thus knowing the true label would help the model discriminate more effectively between them. It selects an instance $x$ such that $$\\arg\\min_{x} P(y_1|x, \\theta) - P(y_2|x, \\theta)$$ where $y_1$ and $y_2$ are the first and second most probable class labels under the model defined by $\\theta$, respectively. If samples from a posterior distributions are provided, it computes $$\\arg\\min_{x} \\mathrm{E}_{p(\\theta| D)} P(y_1|x, \\theta) - \\mathrm{E}_{p(\\theta| D)} P(y_2|x, \\theta)$$ \"\"\" confidence_top2 = confidence ( logits , k = 2 ) # we want the instances with the smallest gap, so we need to negate return - ( confidence_top2 [:, 0 ] - confidence_top2 [:, 1 ]) . flatten ()","title":"margin_confidence()"},{"location":"api/acquisition_functions/#energizer.acquisition_functions.predictive_entropy","text":"Computes the predictive Shannon's entropy in nats. It expects a tensor of logits with the following dimensions: (B: batch_size, C: num_classes, S: num_inference_iterations) . This function implements the following steps, for each element along the B: batch_size dimension: Converts logits in probabilities along the C: num_classes dimension \\( \\(p_{bcs} = e^{l_{bcs}} / \\sum_j e^{l_{bjs}}\\) \\) Averages the output probabilities per class across samples $$p_{bc} = \\frac{1}{S} \\sum_s p_{bcs} Computes Shannon's entropy along the C: num_classes dimension \\( \\(\\mathrm{H}_{b}\\left(\\mathrm{p}(X) \\right) = - \\sum_c p_{bc} \\log(p_{bc})\\) \\) where \\(l_{bcs}\\) is the logit for class \\(c\\) for the \\(b\\) -th element in the batch in the \\(s\\) -th sample, and \\(\\mathrm{p}\\) is a probability mass function for a random variable \\(X\\) such that \\(\\mathrm{p}(X = c) = p_c\\) . You can see the entropy function as a restriction of this in which we only have one sample. Parameters: Name Type Description Default logits Tensor A tensor of dimensions (B: batch_size, C: num_classes, S: num_inference_iterations) . required Returns: Type Description Tensor The Shannon's entropy, i.e. a vector of dimensions (B: batch_size,) . Source code in energizer/acquisition_functions.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 def predictive_entropy ( logits : Tensor ) -> Tensor : r \"\"\"Computes the predictive Shannon's entropy in nats. It expects a tensor of logits with the following dimensions: `(B: batch_size, C: num_classes, S: num_inference_iterations)`. This function implements the following steps, for each element along the `B: batch_size` dimension: - Converts logits in probabilities along the `C: num_classes` dimension $$p_{bcs} = e^{l_{bcs}} / \\sum_j e^{l_{bjs}}$$ - Averages the output probabilities per class across samples $$p_{bc} = \\frac{1}{S} \\sum_s p_{bcs} - Computes Shannon's entropy along the `C: num_classes` dimension $$\\mathrm{H}_{b}\\left(\\mathrm{p}(X) \\right) = - \\sum_c p_{bc} \\log(p_{bc})$$ where $l_{bcs}$ is the logit for class $c$ for the $b$-th element in the batch in the $s$-th sample, and $\\mathrm{p}$ is a probability mass function for a random variable $X$ such that $\\mathrm{p}(X = c) = p_c$. You can see the `entropy` function as a restriction of this in which we only have one sample. Args: logits (Tensor): A tensor of dimensions `(B: batch_size, C: num_classes, S: num_inference_iterations)`. Returns: The Shannon's entropy, i.e. a vector of dimensions `(B: batch_size,)`. \"\"\" avg_probs = logits . softmax ( dim =- 2 ) . mean ( dim =- 1 ) return entr ( avg_probs ) . sum ( dim =- 1 )","title":"predictive_entropy()"},{"location":"api/query_strategies/","text":"Random strategies \u00b6 energizer.query_strategies.RandomStrategy \u00b6 Bases: NoAccumulatorStrategy Query random instances from the pool. Naming conventions In the literature it is sometimes referred to as \"Uniform\" strategy. Source code in energizer/query_strategies/strategies.py 24 25 26 27 28 29 30 31 32 33 class RandomStrategy ( NoAccumulatorStrategy ): \"\"\"Query random instances from the pool. !!! note \"Naming conventions\" In the literature it is sometimes referred to as \"Uniform\" strategy. \"\"\" def query ( self ) -> List [ int ]: pool_size = self . trainer . datamodule . pool_size return np . random . randint ( low = 0 , high = pool_size , size = self . query_size ) . tolist () Uncertainty-based query strategies \u00b6 Uncertainty-based query strategies select instance with high aleatoric uncertainty or epistemic uncertainty. Aleatoric uncertainty refers to the uncertainty in data due the data generation processes (sometimes called irreducible uncertainty). Epistemic uncertainty comes from the modeling/learning process and is caused by a lack of knowledge. energizer.query_strategies.LeastConfidenceStrategy \u00b6 Bases: AccumulatorStrategy Source code in energizer/query_strategies/strategies.py 63 64 65 66 class LeastConfidenceStrategy ( AccumulatorStrategy ): def pool_step ( self , batch : MODEL_INPUT , batch_idx : int , * args , ** kwargs ) -> Tensor : logits = self ( batch ) return least_confidence ( logits ) energizer.query_strategies.MarginStrategy \u00b6 Bases: AccumulatorStrategy Queries instances whose two most likely labels have the smallest difference. In particular, once we collect the posterior probabilities according to the model with parameters \\(\\theta\\) (i.e., the softmax-ed logit), we then compute the difference between the two highest, and use this difference as a measure of uncertainty. In math, \\[ x_H = \\underset{x \\in D_{pool}}{\\arg\\max} \\; p_\\theta(\\hat{y}_1) - p_\\theta(\\hat{y}_2) \\] where \\(\\hat{y}_1\\) and \\(\\hat{y}_2\\) are the first and second most probable class according to the model, respectively. Intuitively, if the classifiers is certain about a prediction, it would assign the majority of the probability mass to a specific class. It implements the entropy calculation using the margin_confidence function. Look the for more details on how it is implemented. Source code in energizer/query_strategies/strategies.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 class MarginStrategy ( AccumulatorStrategy ): r \"\"\"Queries instances whose two most likely labels have the smallest difference. In particular, once we collect the posterior probabilities according to the model with parameters $\\theta$ (i.e., the softmax-ed logit), we then compute the difference between the two highest, and use this difference as a measure of uncertainty. In math, $$ x_H = \\underset{x \\in D_{pool}}{\\arg\\max} \\; p_\\theta(\\hat{y}_1) - p_\\theta(\\hat{y}_2) $$ where $\\hat{y}_1$ and $\\hat{y}_2$ are the first and second most probable class according to the model, respectively. Intuitively, if the classifiers is certain about a prediction, it would assign the majority of the probability mass to a specific class. It implements the entropy calculation using the [`margin_confidence`][energizer.acquisition_functions.margin_confidence] function. Look the for more details on how it is implemented. \"\"\" def pool_step ( self , batch : MODEL_INPUT , batch_idx : int , * args , ** kwargs ) -> Tensor : logits = self ( batch ) return margin_confidence ( logits ) energizer.query_strategies.EntropyStrategy \u00b6 Bases: AccumulatorStrategy Query instances with the highest predictive entropy. This strategy selects instances that maximize the predictive entropy $$ x_H = \\underset{x \\in D_{pool}}{\\arg\\max} \\; \u2212 \\sum_{k=1}^K \\; p_\\theta(y_k \\mid x) \\; \\log p_\\theta(y_k \\mid x) $$ where \\(p_\\theta(y_k \\mid x)\\) is the posterior probability (i.e., the \\(k\\) -th softmax-ed logit) of class \\(k\\) according to the classifier parametrized by the parameters \\(\\theta\\) . It implements the entropy calculation using the entropy function. Look the for more details on how it is implemented. Naming conventions In the literature it is sometimes referred to as \"Max-Entropy\" strategy. Source code in energizer/query_strategies/strategies.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 class EntropyStrategy ( AccumulatorStrategy ): r \"\"\"Query instances with the highest predictive entropy. This strategy selects instances that maximize the predictive entropy $$ x_H = \\underset{x \\in D_{pool}}{\\arg\\max} \\; \u2212 \\sum_{k=1}^K \\; p_\\theta(y_k \\mid x) \\; \\log p_\\theta(y_k \\mid x) $$ where $p_\\theta(y_k \\mid x)$ is the posterior probability (i.e., the $k$-th softmax-ed logit) of class $k$ according to the classifier parametrized by the parameters $\\theta$. It implements the entropy calculation using the [`entropy`][energizer.acquisition_functions.entropy] function. Look the for more details on how it is implemented. !!! note \"Naming conventions\" In the literature it is sometimes referred to as \"Max-Entropy\" strategy. \"\"\" def pool_step ( self , batch : MODEL_INPUT , batch_idx : int , * args , ** kwargs ) -> Tensor : logits = self ( batch ) return entropy ( logits ) Base classes \u00b6 BaseQueryStrategy \u00b6 Bases: LightningModule , ModelHooks Source code in energizer/query_strategies/base.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 class BaseQueryStrategy ( LightningModule , ModelHooks , metaclass = PostInitCaller ): def __init__ ( self , model : LightningModule ) -> None : super () . __init__ () self . model = deepcopy ( model ) def __post_init__ ( self ) -> None : raise NotImplementedError ( \"You need to attach a pool loop.\" ) def __call__ ( self , * args , ** kwargs ) -> Any : return self . _forward ( * args , ** kwargs ) @property def pool_loop ( self ) -> Loop : return self . _pool_loop @pool_loop . setter def pool_loop ( self , pool_loop ) -> None : self . _pool_loop = pool_loop @property def query_size ( self ) -> int : return self . _query_size @query_size . setter def query_size ( self , query_size : int ) -> None : self . _query_size = query_size def query ( self ) -> List [ int ]: \"\"\"Queries instances from the unlabeled pool. A query selects instances from the unlabeled pool. \"\"\" raise NotImplementedError ( \"You need to define how the pool is queried.\" ) def _forward ( self , * args , ** kwargs ) -> Any : return self . model . forward ( * args , ** kwargs ) def get_inputs_from_batch ( self , batch : BATCH_TYPE ) -> MODEL_INPUT : return batch query () \u00b6 Queries instances from the unlabeled pool. A query selects instances from the unlabeled pool. Source code in energizer/query_strategies/base.py 53 54 55 56 57 58 def query ( self ) -> List [ int ]: \"\"\"Queries instances from the unlabeled pool. A query selects instances from the unlabeled pool. \"\"\" raise NotImplementedError ( \"You need to define how the pool is queried.\" ) MCAccumulatorStrategy \u00b6 Bases: AccumulatorStrategy Implements the MCDropout inference method in [PUT REFERENCES]. Source code in energizer/query_strategies/base.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 class MCAccumulatorStrategy ( AccumulatorStrategy ): \"\"\"Implements the MCDropout inference method in [PUT REFERENCES].\"\"\" def __init__ ( self , model : LightningModule , num_inference_iters : Optional [ int ] = 10 , consistent : Optional [ bool ] = False , prob : Optional [ float ] = None , ) -> None : \"\"\"Instantiates a new learner (same as `learner`) with patched dropout layers. The patched such that they are active even during evaluation. Args: num_inference_iters (int): The number of forward passes to perform. consistent (bool): If True, it uses the consistent version of dropout that fixes the mask across batches. prob (float): If specified, this changes the dropout probability of all layers to `prob`. If `None` the dropout probability is the same as the original layer. Must be 0 <= prob <= 1. inplace (bool): Whether to modify the learner in place or return a copy of the learner. \"\"\" self . num_inference_iters = num_inference_iters self . consistent = consistent self . prob = prob super () . __init__ ( model ) def __post_init__ ( self ) -> None : super () . __post_init__ () patch_dropout_layers ( module = self . model , prob = self . prob , consistent = self . consistent , inplace = True , ) def _forward ( self , * args , ** kwargs ) -> Tensor : \"\"\"Performs `num_inference_iters` forward passes using the underlying learner and keeping the dropout layers active.. Returns: A tensor of dimension `(B: batch_size, C: num_classes, S: num_samples)`. \"\"\" out = [] for _ in range ( self . num_inference_iters ): out . append ( self . model . forward ( * args , ** kwargs )) # type: ignore # expects shape [num_samples, num_classes, num_iterations] return torch . stack ( out ) . permute (( 1 , 2 , 0 )) __init__ ( model , num_inference_iters = 10 , consistent = False , prob = None ) \u00b6 Instantiates a new learner (same as learner ) with patched dropout layers. The patched such that they are active even during evaluation. Parameters: Name Type Description Default num_inference_iters int The number of forward passes to perform. 10 consistent bool If True, it uses the consistent version of dropout that fixes the mask across batches. False prob float If specified, this changes the dropout probability of all layers to prob . If None the dropout probability is the same as the original layer. Must be 0 <= prob <= 1. None inplace bool Whether to modify the learner in place or return a copy of the learner. required Source code in energizer/query_strategies/base.py 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 def __init__ ( self , model : LightningModule , num_inference_iters : Optional [ int ] = 10 , consistent : Optional [ bool ] = False , prob : Optional [ float ] = None , ) -> None : \"\"\"Instantiates a new learner (same as `learner`) with patched dropout layers. The patched such that they are active even during evaluation. Args: num_inference_iters (int): The number of forward passes to perform. consistent (bool): If True, it uses the consistent version of dropout that fixes the mask across batches. prob (float): If specified, this changes the dropout probability of all layers to `prob`. If `None` the dropout probability is the same as the original layer. Must be 0 <= prob <= 1. inplace (bool): Whether to modify the learner in place or return a copy of the learner. \"\"\" self . num_inference_iters = num_inference_iters self . consistent = consistent self . prob = prob super () . __init__ ( model ) PostInitCaller \u00b6 Bases: type Used to call setup automatically after __init__ . Source code in energizer/query_strategies/base.py 16 17 18 19 20 21 22 23 class PostInitCaller ( type ): \"\"\"Used to call `setup` automatically after `__init__`.\"\"\" def __call__ ( cls , * args , ** kwargs ): \"\"\"Called when you call `MyNewClass()`.\"\"\" obj = type . __call__ ( cls , * args , ** kwargs ) obj . __post_init__ () return obj __call__ ( * args , ** kwargs ) \u00b6 Called when you call MyNewClass() . Source code in energizer/query_strategies/base.py 19 20 21 22 23 def __call__ ( cls , * args , ** kwargs ): \"\"\"Called when you call `MyNewClass()`.\"\"\" obj = type . __call__ ( cls , * args , ** kwargs ) obj . __post_init__ () return obj","title":"Query strategies"},{"location":"api/query_strategies/#random-strategies","text":"","title":"Random strategies"},{"location":"api/query_strategies/#energizer.query_strategies.RandomStrategy","text":"Bases: NoAccumulatorStrategy Query random instances from the pool. Naming conventions In the literature it is sometimes referred to as \"Uniform\" strategy. Source code in energizer/query_strategies/strategies.py 24 25 26 27 28 29 30 31 32 33 class RandomStrategy ( NoAccumulatorStrategy ): \"\"\"Query random instances from the pool. !!! note \"Naming conventions\" In the literature it is sometimes referred to as \"Uniform\" strategy. \"\"\" def query ( self ) -> List [ int ]: pool_size = self . trainer . datamodule . pool_size return np . random . randint ( low = 0 , high = pool_size , size = self . query_size ) . tolist ()","title":"RandomStrategy"},{"location":"api/query_strategies/#uncertainty-based-query-strategies","text":"Uncertainty-based query strategies select instance with high aleatoric uncertainty or epistemic uncertainty. Aleatoric uncertainty refers to the uncertainty in data due the data generation processes (sometimes called irreducible uncertainty). Epistemic uncertainty comes from the modeling/learning process and is caused by a lack of knowledge.","title":"Uncertainty-based query strategies"},{"location":"api/query_strategies/#energizer.query_strategies.LeastConfidenceStrategy","text":"Bases: AccumulatorStrategy Source code in energizer/query_strategies/strategies.py 63 64 65 66 class LeastConfidenceStrategy ( AccumulatorStrategy ): def pool_step ( self , batch : MODEL_INPUT , batch_idx : int , * args , ** kwargs ) -> Tensor : logits = self ( batch ) return least_confidence ( logits )","title":"LeastConfidenceStrategy"},{"location":"api/query_strategies/#energizer.query_strategies.MarginStrategy","text":"Bases: AccumulatorStrategy Queries instances whose two most likely labels have the smallest difference. In particular, once we collect the posterior probabilities according to the model with parameters \\(\\theta\\) (i.e., the softmax-ed logit), we then compute the difference between the two highest, and use this difference as a measure of uncertainty. In math, \\[ x_H = \\underset{x \\in D_{pool}}{\\arg\\max} \\; p_\\theta(\\hat{y}_1) - p_\\theta(\\hat{y}_2) \\] where \\(\\hat{y}_1\\) and \\(\\hat{y}_2\\) are the first and second most probable class according to the model, respectively. Intuitively, if the classifiers is certain about a prediction, it would assign the majority of the probability mass to a specific class. It implements the entropy calculation using the margin_confidence function. Look the for more details on how it is implemented. Source code in energizer/query_strategies/strategies.py 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 class MarginStrategy ( AccumulatorStrategy ): r \"\"\"Queries instances whose two most likely labels have the smallest difference. In particular, once we collect the posterior probabilities according to the model with parameters $\\theta$ (i.e., the softmax-ed logit), we then compute the difference between the two highest, and use this difference as a measure of uncertainty. In math, $$ x_H = \\underset{x \\in D_{pool}}{\\arg\\max} \\; p_\\theta(\\hat{y}_1) - p_\\theta(\\hat{y}_2) $$ where $\\hat{y}_1$ and $\\hat{y}_2$ are the first and second most probable class according to the model, respectively. Intuitively, if the classifiers is certain about a prediction, it would assign the majority of the probability mass to a specific class. It implements the entropy calculation using the [`margin_confidence`][energizer.acquisition_functions.margin_confidence] function. Look the for more details on how it is implemented. \"\"\" def pool_step ( self , batch : MODEL_INPUT , batch_idx : int , * args , ** kwargs ) -> Tensor : logits = self ( batch ) return margin_confidence ( logits )","title":"MarginStrategy"},{"location":"api/query_strategies/#energizer.query_strategies.EntropyStrategy","text":"Bases: AccumulatorStrategy Query instances with the highest predictive entropy. This strategy selects instances that maximize the predictive entropy $$ x_H = \\underset{x \\in D_{pool}}{\\arg\\max} \\; \u2212 \\sum_{k=1}^K \\; p_\\theta(y_k \\mid x) \\; \\log p_\\theta(y_k \\mid x) $$ where \\(p_\\theta(y_k \\mid x)\\) is the posterior probability (i.e., the \\(k\\) -th softmax-ed logit) of class \\(k\\) according to the classifier parametrized by the parameters \\(\\theta\\) . It implements the entropy calculation using the entropy function. Look the for more details on how it is implemented. Naming conventions In the literature it is sometimes referred to as \"Max-Entropy\" strategy. Source code in energizer/query_strategies/strategies.py 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 class EntropyStrategy ( AccumulatorStrategy ): r \"\"\"Query instances with the highest predictive entropy. This strategy selects instances that maximize the predictive entropy $$ x_H = \\underset{x \\in D_{pool}}{\\arg\\max} \\; \u2212 \\sum_{k=1}^K \\; p_\\theta(y_k \\mid x) \\; \\log p_\\theta(y_k \\mid x) $$ where $p_\\theta(y_k \\mid x)$ is the posterior probability (i.e., the $k$-th softmax-ed logit) of class $k$ according to the classifier parametrized by the parameters $\\theta$. It implements the entropy calculation using the [`entropy`][energizer.acquisition_functions.entropy] function. Look the for more details on how it is implemented. !!! note \"Naming conventions\" In the literature it is sometimes referred to as \"Max-Entropy\" strategy. \"\"\" def pool_step ( self , batch : MODEL_INPUT , batch_idx : int , * args , ** kwargs ) -> Tensor : logits = self ( batch ) return entropy ( logits )","title":"EntropyStrategy"},{"location":"api/query_strategies/#base-classes","text":"","title":"Base classes"},{"location":"api/query_strategies/#energizer.query_strategies.base.BaseQueryStrategy","text":"Bases: LightningModule , ModelHooks Source code in energizer/query_strategies/base.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 class BaseQueryStrategy ( LightningModule , ModelHooks , metaclass = PostInitCaller ): def __init__ ( self , model : LightningModule ) -> None : super () . __init__ () self . model = deepcopy ( model ) def __post_init__ ( self ) -> None : raise NotImplementedError ( \"You need to attach a pool loop.\" ) def __call__ ( self , * args , ** kwargs ) -> Any : return self . _forward ( * args , ** kwargs ) @property def pool_loop ( self ) -> Loop : return self . _pool_loop @pool_loop . setter def pool_loop ( self , pool_loop ) -> None : self . _pool_loop = pool_loop @property def query_size ( self ) -> int : return self . _query_size @query_size . setter def query_size ( self , query_size : int ) -> None : self . _query_size = query_size def query ( self ) -> List [ int ]: \"\"\"Queries instances from the unlabeled pool. A query selects instances from the unlabeled pool. \"\"\" raise NotImplementedError ( \"You need to define how the pool is queried.\" ) def _forward ( self , * args , ** kwargs ) -> Any : return self . model . forward ( * args , ** kwargs ) def get_inputs_from_batch ( self , batch : BATCH_TYPE ) -> MODEL_INPUT : return batch","title":"BaseQueryStrategy"},{"location":"api/query_strategies/#energizer.query_strategies.base.BaseQueryStrategy.query","text":"Queries instances from the unlabeled pool. A query selects instances from the unlabeled pool. Source code in energizer/query_strategies/base.py 53 54 55 56 57 58 def query ( self ) -> List [ int ]: \"\"\"Queries instances from the unlabeled pool. A query selects instances from the unlabeled pool. \"\"\" raise NotImplementedError ( \"You need to define how the pool is queried.\" )","title":"query()"},{"location":"api/query_strategies/#energizer.query_strategies.base.MCAccumulatorStrategy","text":"Bases: AccumulatorStrategy Implements the MCDropout inference method in [PUT REFERENCES]. Source code in energizer/query_strategies/base.py 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 class MCAccumulatorStrategy ( AccumulatorStrategy ): \"\"\"Implements the MCDropout inference method in [PUT REFERENCES].\"\"\" def __init__ ( self , model : LightningModule , num_inference_iters : Optional [ int ] = 10 , consistent : Optional [ bool ] = False , prob : Optional [ float ] = None , ) -> None : \"\"\"Instantiates a new learner (same as `learner`) with patched dropout layers. The patched such that they are active even during evaluation. Args: num_inference_iters (int): The number of forward passes to perform. consistent (bool): If True, it uses the consistent version of dropout that fixes the mask across batches. prob (float): If specified, this changes the dropout probability of all layers to `prob`. If `None` the dropout probability is the same as the original layer. Must be 0 <= prob <= 1. inplace (bool): Whether to modify the learner in place or return a copy of the learner. \"\"\" self . num_inference_iters = num_inference_iters self . consistent = consistent self . prob = prob super () . __init__ ( model ) def __post_init__ ( self ) -> None : super () . __post_init__ () patch_dropout_layers ( module = self . model , prob = self . prob , consistent = self . consistent , inplace = True , ) def _forward ( self , * args , ** kwargs ) -> Tensor : \"\"\"Performs `num_inference_iters` forward passes using the underlying learner and keeping the dropout layers active.. Returns: A tensor of dimension `(B: batch_size, C: num_classes, S: num_samples)`. \"\"\" out = [] for _ in range ( self . num_inference_iters ): out . append ( self . model . forward ( * args , ** kwargs )) # type: ignore # expects shape [num_samples, num_classes, num_iterations] return torch . stack ( out ) . permute (( 1 , 2 , 0 ))","title":"MCAccumulatorStrategy"},{"location":"api/query_strategies/#energizer.query_strategies.base.MCAccumulatorStrategy.__init__","text":"Instantiates a new learner (same as learner ) with patched dropout layers. The patched such that they are active even during evaluation. Parameters: Name Type Description Default num_inference_iters int The number of forward passes to perform. 10 consistent bool If True, it uses the consistent version of dropout that fixes the mask across batches. False prob float If specified, this changes the dropout probability of all layers to prob . If None the dropout probability is the same as the original layer. Must be 0 <= prob <= 1. None inplace bool Whether to modify the learner in place or return a copy of the learner. required Source code in energizer/query_strategies/base.py 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 def __init__ ( self , model : LightningModule , num_inference_iters : Optional [ int ] = 10 , consistent : Optional [ bool ] = False , prob : Optional [ float ] = None , ) -> None : \"\"\"Instantiates a new learner (same as `learner`) with patched dropout layers. The patched such that they are active even during evaluation. Args: num_inference_iters (int): The number of forward passes to perform. consistent (bool): If True, it uses the consistent version of dropout that fixes the mask across batches. prob (float): If specified, this changes the dropout probability of all layers to `prob`. If `None` the dropout probability is the same as the original layer. Must be 0 <= prob <= 1. inplace (bool): Whether to modify the learner in place or return a copy of the learner. \"\"\" self . num_inference_iters = num_inference_iters self . consistent = consistent self . prob = prob super () . __init__ ( model )","title":"__init__()"},{"location":"api/query_strategies/#energizer.query_strategies.base.PostInitCaller","text":"Bases: type Used to call setup automatically after __init__ . Source code in energizer/query_strategies/base.py 16 17 18 19 20 21 22 23 class PostInitCaller ( type ): \"\"\"Used to call `setup` automatically after `__init__`.\"\"\" def __call__ ( cls , * args , ** kwargs ): \"\"\"Called when you call `MyNewClass()`.\"\"\" obj = type . __call__ ( cls , * args , ** kwargs ) obj . __post_init__ () return obj","title":"PostInitCaller"},{"location":"api/query_strategies/#energizer.query_strategies.base.PostInitCaller.__call__","text":"Called when you call MyNewClass() . Source code in energizer/query_strategies/base.py 19 20 21 22 23 def __call__ ( cls , * args , ** kwargs ): \"\"\"Called when you call `MyNewClass()`.\"\"\" obj = type . __call__ ( cls , * args , ** kwargs ) obj . __post_init__ () return obj","title":"__call__()"},{"location":"api/trainer/","text":"Trainer \u00b6 Bases: pl . Trainer Source code in energizer/trainer.py 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 class Trainer ( pl . Trainer ): def __init__ ( self , query_size : int = 2 , reset_weights : Optional [ bool ] = True , test_after_labelling : Optional [ bool ] = False , total_budget : Optional [ int ] = - 1 , min_labelling_epochs : Optional [ int ] = 0 , max_labelling_epochs : Optional [ int ] = - 1 , limit_pool_batches : Optional [ Union [ int , float ]] = None , ** kwargs , ) -> None : # initialize lightning trainer super () . __init__ ( ** kwargs ) # register inputs self . query_size = query_size self . reset_weights = reset_weights self . test_after_labelling = test_after_labelling self . total_budget = total_budget self . min_labelling_epochs = min_labelling_epochs self . max_labelling_epochs = max_labelling_epochs self . limit_pool_batches = limit_pool_batches # used to decide which `_run_train()` method to run` self . active_fitting : bool = False # overwrite data_connector in trainer self . _data_connector = DataConnector ( self , self . _data_connector . multiple_trainloader_mode ) self . _data_connector . on_trainer_init ( val_check_interval = self . val_check_interval , check_val_every_n_epoch = self . check_val_every_n_epoch , reload_dataloaders_every_n_epochs = self . reload_dataloaders_every_n_epochs , ) # fit after each labelling session fit_loop = FitLoop ( min_epochs = self . fit_loop . min_epochs , max_epochs = self . fit_loop . max_epochs ) training_epoch_loop = TrainingEpochLoop ( min_steps = self . fit_loop . min_steps , max_steps = self . fit_loop . max_steps ) fit_loop . connect ( epoch_loop = training_epoch_loop ) # test after labelling and fitting test_loop = EvaluationLoop ( verbose = False ) # main active learning loop active_learning_loop = ActiveLearningLoop ( reset_weights = self . reset_weights , total_budget = self . total_budget , test_after_labelling = self . test_after_labelling , min_labelling_epochs = self . min_labelling_epochs , max_labelling_epochs = self . max_labelling_epochs , ) active_learning_loop . connect ( pool_loop = None , fit_loop = fit_loop , test_loop = test_loop ) self . active_learning_loop = active_learning_loop # also attaches the trainer # this needed to be patched self . _extend_setup_on_init () self . _extend_init_debugging_flags () \"\"\" Properties \"\"\" @property def active_fitting ( self ) -> bool : return self . _active_fitting @active_fitting . setter def active_fitting ( self , active_fitting : bool ) -> None : self . _active_fitting = active_fitting @property def active_learning_loop ( self ) -> FitLoop : return self . _active_learning_loop @active_learning_loop . setter def active_learning_loop ( self , loop : ActiveLearningLoop ): \"\"\"Attach a custom active_learning_loop to this Trainer.\"\"\" loop . trainer = self self . _active_learning_loop = loop @property def query_strategy ( self ) -> BaseQueryStrategy : return self . _query_strategy @query_strategy . setter def query_strategy ( self , model : BaseQueryStrategy ): \"\"\"Attach a custom query_strategy to this Trainer.\"\"\" self . _query_strategy = model \"\"\" New `active_fit` method \"\"\" def active_fit ( self , model : BaseQueryStrategy , train_dataloaders : Optional [ Union [ TRAIN_DATALOADERS , \"pl.LightningDataModule\" ]] = None , val_dataloaders : Optional [ EVAL_DATALOADERS ] = None , test_dataloaders : Optional [ EVAL_DATALOADERS ] = None , datamodule : Optional [ \"pl.LightningDataModule\" ] = None , ckpt_path : Optional [ str ] = None , ) -> List [ LabellingIterOutputs ]: # set up model reference self . query_strategy = model self . query_strategy . query_size = self . query_size self . active_learning_loop . pool_loop = self . query_strategy . pool_loop \"\"\" NOTE: this creates the `self.lightning_module` attribute on the trainer it is set in the `fit` method, but we do not set it here and let the loop components do it \"\"\" # self.strategy.model = model return self . _call_and_handle_interrupt ( self . _active_fit_impl , self . query_strategy , train_dataloaders , val_dataloaders , test_dataloaders , datamodule , ckpt_path , ) def _active_fit_impl ( self , model : BaseQueryStrategy , train_dataloaders : Optional [ Union [ TRAIN_DATALOADERS , \"pl.LightningDataModule\" ]] = None , val_dataloaders : Optional [ EVAL_DATALOADERS ] = None , test_dataloaders : Optional [ EVAL_DATALOADERS ] = None , datamodule : Optional [ \"pl.LightningDataModule\" ] = None , ckpt_path : Optional [ str ] = None , ) -> None : \"\"\" Check the inputs \"\"\" # check inputs if not isinstance ( model , BaseQueryStrategy ): raise MisconfigurationException ( f \"model must be a `BaseQueryStrategy` not { type ( model ) . __class__ . __name__ } .\" ) # if a datamodule comes in as the second arg, then fix it for the user if isinstance ( train_dataloaders , pl . LightningDataModule ): datamodule = train_dataloaders train_dataloaders = None is_dataloaders = train_dataloaders is not None or val_dataloaders is not None or test_dataloaders is not None is_datamodule = datamodule is not None # if you supply a datamodule you can't supply train_dataloader or val_dataloaders if is_dataloaders and is_datamodule : raise MisconfigurationException ( \"You cannot pass `train_dataloader` or `val_dataloaders` or \" , \"`test_dataloaders` to `trainer.active_fit(datamodule=...)`\" , ) # cast to ActiveDataModule elif is_dataloaders or ( is_datamodule and not isinstance ( datamodule , ActiveDataModule )): datamodule = ActiveDataModule ( train_dataloader = train_dataloaders , val_dataloaders = val_dataloaders , test_dataloaders = test_dataloaders , datamodule = datamodule , ) # check if can run testing if self . test_after_labelling and getattr ( datamodule , \"test_dataloader\" , None ) is None : raise MisconfigurationException ( \"You specified `test_after_labelling=True` but no test_dataloader was provided.\" ) \"\"\" Set states \"\"\" # patch progress bar and add pool-related hooks _old_callbacks = self . callbacks self . callbacks = patch_callbacks ( self . callbacks ) # set states as in the original `_fit_impl` self . active_fitting = True # TODO: some of these are duplicated in the `reset_{fitting, test}` methods in `ActiveLearningLoop` pl . Trainer . _log_api_event ( \"fit\" ) logger . info ( f \" { self . __class__ . __name__ } : trainer active_fit stage\" ) self . state . fn = TrainerFn . FITTING self . state . status = TrainerStatus . RUNNING self . training = True self . _last_train_dl_reload_epoch = float ( \"-inf\" ) self . _last_val_dl_reload_epoch = float ( \"-inf\" ) self . _last_test_dl_reload_epoch = float ( \"-inf\" ) # links data to the trainer self . _data_connector . attach_data ( model , datamodule = datamodule ) # TODO: ckpt_path only in v2.0 ckpt_path = ckpt_path or self . resume_from_checkpoint self . _ckpt_path = self . __set_ckpt_path ( ckpt_path , model_provided = True , model_connected = self . lightning_module is not None ) \"\"\" Run active fit loop \"\"\" # NOTE: pass the underlying `LightningModule` to `_run` so that it finds # the `training_step` method etc results = self . _run ( model . model , ckpt_path = self . ckpt_path ) \"\"\" Reset states \"\"\" assert self . state . stopped self . training = False self . active_fitting = False # reset original callbacks self . callbacks = _old_callbacks return results def reset_pool_dataloader ( self , model : Optional [ \"pl.LightningModule\" ] = None ) -> None : \"\"\"Resets the pool dataloader and determines the number of batches. This method is exactly the same as `trainer.reset_test_dataloader`. Args: model: The ``LightningModule`` if called outside of the trainer scope. \"\"\" # source = self._data_connector._pool_dataloader_source pl_module = self . lightning_module or model # has_step = is_overridden(\"pool_step\", pl_module, BaseQueryStrategy) enable_pool = self . limit_pool_batches > 0 # if has_step and enable_pool: if enable_pool : self . num_pool_batches , self . pool_dataloaders = self . _data_connector . _reset_eval_dataloader ( PoolRunningStage . POOL , model = pl_module ) \"\"\" Extend methods that need to be called in the `__init__` \"\"\" def _extend_init_debugging_flags ( self ) -> None : \"\"\"This method extends the original `trainer._init_debugging_flags` method.\"\"\" if self . fast_dev_run : num_batches = int ( self . fast_dev_run ) self . limit_pool_batches = num_batches self . fit_loop . max_steps = num_batches self . fit_loop . max_epochs = 1 self . limit_pool_batches = _determine_batch_limits ( self . limit_pool_batches , \"limit_pool_batches\" ) def _extend_setup_on_init ( self ) -> None : \"\"\"This method extends the original `trainer._setup_on_init` method.\"\"\" self . num_pool_batches = [] self . pool_dataloaders = None \"\"\" Patch `_run_train` implementation \"\"\" def _run_train ( self ) -> List [ LabellingIterOutputs ]: \"\"\"Method that depending on `self.active_fitting` selects which loop to run. If `self.active_fitting is False` it runs the usual `fit_loop`, otherwise runs the `active_learning_loop`. \"\"\" if not self . active_fitting : # run normal fit_loop return super () . _run_train () # NOTE: this exactly mimics what they do in `super()._run_train()` self . _pre_training_routine () with isolate_rng (): self . _run_sanity_check () # enable train mode self . model . train () torch . set_grad_enabled ( True ) self . active_learning_loop . trainer = self with torch . autograd . set_detect_anomaly ( self . _detect_anomaly ): results = self . active_learning_loop . run () return results \"\"\" Dispatch properties calls to the right `FitLoop` depending on whether we are `active_fitting` or simply training \"\"\" @property def global_step ( self ) -> int : \"\"\"The number of optimizer steps taken (does not reset each epoch). This includes multiple optimizers and TBPTT steps (if enabled). \"\"\" if self . active_fitting : return self . active_learning_loop . fit_loop . epoch_loop . global_step return self . fit_loop . epoch_loop . global_step @property def current_epoch ( self ) -> int : \"\"\"The current epoch, updated after the epoch end hooks are run.\"\"\" if self . active_fitting : return self . active_learning_loop . fit_loop . epoch_progress . current . completed return self . fit_loop . epoch_progress . current . completed @property def max_epochs ( self ) -> int : if self . active_fitting : return self . active_learning_loop . fit_loop . max_epochs return self . fit_loop . max_epochs @property def min_epochs ( self ) -> int : if self . active_fitting : return self . active_learning_loop . fit_loop . min_epochs return self . fit_loop . min_epochs @property def max_steps ( self ) -> int : if self . active_fitting : return self . active_learning_loop . fit_loop . max_steps return self . fit_loop . max_steps @property def min_steps ( self ) -> Optional [ int ]: if self . active_fitting : return self . active_learning_loop . fit_loop . min_steps return self . fit_loop . min_steps @property def is_last_batch ( self ) -> bool : \"\"\"Whether trainer is executing the last batch.\"\"\" if self . active_fitting : return self . active_learning_loop . fit_loop . epoch_loop . batch_progress . is_last_batch return self . fit_loop . epoch_loop . batch_progress . is_last_batch @property def _evaluation_loop ( self ) -> EvaluationLoop : if self . state . fn in ( TrainerFn . FITTING , TrainerFn . TUNING ): return ( self . fit_loop . epoch_loop . val_loop if not self . active_fitting else self . active_learning_loop . fit_loop . epoch_loop . val_loop ) if self . state . fn == TrainerFn . VALIDATING : return ( self . validate_loop if not self . active_fitting else self . active_learning_loop . fit_loop . epoch_loop . val_loop ) if self . state . fn == TrainerFn . TESTING : return self . test_loop if not self . active_fitting else self . active_learning_loop . test_loop raise RuntimeError ( \"The `Trainer._evaluation_loop` property isn't defined. Accessed outside of scope\" ) @property def _active_loop ( self ) -> Optional [ Union [ FitLoop , EvaluationLoop , PredictionLoop ]]: \"\"\"Returns the currently active loop based on the `Trainer`'s state.\"\"\" if self . training : return self . fit_loop if not self . active_fitting else self . active_learning_loop if self . sanity_checking or self . evaluating : # this resolves the `active_fitting` condition internally return self . _evaluation_loop if self . predicting : return self . predict_loop def set_lightning_module ( self , use_query_strategy : bool = False ) -> None : if use_query_strategy : # self.strategy.model = self.query_strategy self . strategy . connect ( self . query_strategy ) logger . debug ( f \"Using ` { self . lightning_module . __class__ . __name__ } `\" ) else : # self.strategy.model = self.query_strategy.model self . strategy . connect ( self . query_strategy . model ) logger . debug ( f \"Using underlying ` { self . lightning_module . __class__ . __name__ } `\" ) self . strategy . model_to_device () @property def using_query_strategy_as_lightning_module ( self ) -> bool : return isinstance ( self . lightning_module , BaseQueryStrategy ) current_epoch () property \u00b6 The current epoch, updated after the epoch end hooks are run. Source code in energizer/trainer.py 387 388 389 390 391 392 @property def current_epoch ( self ) -> int : \"\"\"The current epoch, updated after the epoch end hooks are run.\"\"\" if self . active_fitting : return self . active_learning_loop . fit_loop . epoch_progress . current . completed return self . fit_loop . epoch_progress . current . completed global_step () property \u00b6 The number of optimizer steps taken (does not reset each epoch). This includes multiple optimizers and TBPTT steps (if enabled). Source code in energizer/trainer.py 377 378 379 380 381 382 383 384 385 @property def global_step ( self ) -> int : \"\"\"The number of optimizer steps taken (does not reset each epoch). This includes multiple optimizers and TBPTT steps (if enabled). \"\"\" if self . active_fitting : return self . active_learning_loop . fit_loop . epoch_loop . global_step return self . fit_loop . epoch_loop . global_step is_last_batch () property \u00b6 Whether trainer is executing the last batch. Source code in energizer/trainer.py 418 419 420 421 422 423 @property def is_last_batch ( self ) -> bool : \"\"\"Whether trainer is executing the last batch.\"\"\" if self . active_fitting : return self . active_learning_loop . fit_loop . epoch_loop . batch_progress . is_last_batch return self . fit_loop . epoch_loop . batch_progress . is_last_batch reset_pool_dataloader ( model = None ) \u00b6 Resets the pool dataloader and determines the number of batches. This method is exactly the same as trainer.reset_test_dataloader . Parameters: Name Type Description Default model Optional [ LightningModule ] The LightningModule if called outside of the trainer scope. None Source code in energizer/trainer.py 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 def reset_pool_dataloader ( self , model : Optional [ \"pl.LightningModule\" ] = None ) -> None : \"\"\"Resets the pool dataloader and determines the number of batches. This method is exactly the same as `trainer.reset_test_dataloader`. Args: model: The ``LightningModule`` if called outside of the trainer scope. \"\"\" # source = self._data_connector._pool_dataloader_source pl_module = self . lightning_module or model # has_step = is_overridden(\"pool_step\", pl_module, BaseQueryStrategy) enable_pool = self . limit_pool_batches > 0 # if has_step and enable_pool: if enable_pool : self . num_pool_batches , self . pool_dataloaders = self . _data_connector . _reset_eval_dataloader ( PoolRunningStage . POOL , model = pl_module ) patch_callbacks ( callbacks ) \u00b6 Adds pool -related hooks to callbacks. Source code in energizer/trainer.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def patch_callbacks ( callbacks : List [ Callback ]) -> List [ Callback ]: \"\"\"Adds `pool`-related hooks to callbacks.\"\"\" def add_pool_hooks ( callback : Callback ) -> Callback : hook_names = [ m for m in dir ( CallBackActiveLearningHooks ) if not m . startswith ( \"_\" )] for name in hook_names : if not hasattr ( callback , name ): setattr ( callback , name , getattr ( CallBackActiveLearningHooks , name )) return callback new_callbacks = [] for c in callbacks : if isinstance ( c , ProgressBarBase ): prog_bar = TQDMProgressBarActiveLearning ( process_position = c . process_position , refresh_rate = c . refresh_rate ) prog_bar = add_pool_hooks ( prog_bar ) new_callbacks . append ( prog_bar ) else : new_callbacks . append ( add_pool_hooks ( c )) return new_callbacks","title":"Trainer"},{"location":"api/trainer/#energizer.trainer.Trainer","text":"Bases: pl . Trainer Source code in energizer/trainer.py 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 class Trainer ( pl . Trainer ): def __init__ ( self , query_size : int = 2 , reset_weights : Optional [ bool ] = True , test_after_labelling : Optional [ bool ] = False , total_budget : Optional [ int ] = - 1 , min_labelling_epochs : Optional [ int ] = 0 , max_labelling_epochs : Optional [ int ] = - 1 , limit_pool_batches : Optional [ Union [ int , float ]] = None , ** kwargs , ) -> None : # initialize lightning trainer super () . __init__ ( ** kwargs ) # register inputs self . query_size = query_size self . reset_weights = reset_weights self . test_after_labelling = test_after_labelling self . total_budget = total_budget self . min_labelling_epochs = min_labelling_epochs self . max_labelling_epochs = max_labelling_epochs self . limit_pool_batches = limit_pool_batches # used to decide which `_run_train()` method to run` self . active_fitting : bool = False # overwrite data_connector in trainer self . _data_connector = DataConnector ( self , self . _data_connector . multiple_trainloader_mode ) self . _data_connector . on_trainer_init ( val_check_interval = self . val_check_interval , check_val_every_n_epoch = self . check_val_every_n_epoch , reload_dataloaders_every_n_epochs = self . reload_dataloaders_every_n_epochs , ) # fit after each labelling session fit_loop = FitLoop ( min_epochs = self . fit_loop . min_epochs , max_epochs = self . fit_loop . max_epochs ) training_epoch_loop = TrainingEpochLoop ( min_steps = self . fit_loop . min_steps , max_steps = self . fit_loop . max_steps ) fit_loop . connect ( epoch_loop = training_epoch_loop ) # test after labelling and fitting test_loop = EvaluationLoop ( verbose = False ) # main active learning loop active_learning_loop = ActiveLearningLoop ( reset_weights = self . reset_weights , total_budget = self . total_budget , test_after_labelling = self . test_after_labelling , min_labelling_epochs = self . min_labelling_epochs , max_labelling_epochs = self . max_labelling_epochs , ) active_learning_loop . connect ( pool_loop = None , fit_loop = fit_loop , test_loop = test_loop ) self . active_learning_loop = active_learning_loop # also attaches the trainer # this needed to be patched self . _extend_setup_on_init () self . _extend_init_debugging_flags () \"\"\" Properties \"\"\" @property def active_fitting ( self ) -> bool : return self . _active_fitting @active_fitting . setter def active_fitting ( self , active_fitting : bool ) -> None : self . _active_fitting = active_fitting @property def active_learning_loop ( self ) -> FitLoop : return self . _active_learning_loop @active_learning_loop . setter def active_learning_loop ( self , loop : ActiveLearningLoop ): \"\"\"Attach a custom active_learning_loop to this Trainer.\"\"\" loop . trainer = self self . _active_learning_loop = loop @property def query_strategy ( self ) -> BaseQueryStrategy : return self . _query_strategy @query_strategy . setter def query_strategy ( self , model : BaseQueryStrategy ): \"\"\"Attach a custom query_strategy to this Trainer.\"\"\" self . _query_strategy = model \"\"\" New `active_fit` method \"\"\" def active_fit ( self , model : BaseQueryStrategy , train_dataloaders : Optional [ Union [ TRAIN_DATALOADERS , \"pl.LightningDataModule\" ]] = None , val_dataloaders : Optional [ EVAL_DATALOADERS ] = None , test_dataloaders : Optional [ EVAL_DATALOADERS ] = None , datamodule : Optional [ \"pl.LightningDataModule\" ] = None , ckpt_path : Optional [ str ] = None , ) -> List [ LabellingIterOutputs ]: # set up model reference self . query_strategy = model self . query_strategy . query_size = self . query_size self . active_learning_loop . pool_loop = self . query_strategy . pool_loop \"\"\" NOTE: this creates the `self.lightning_module` attribute on the trainer it is set in the `fit` method, but we do not set it here and let the loop components do it \"\"\" # self.strategy.model = model return self . _call_and_handle_interrupt ( self . _active_fit_impl , self . query_strategy , train_dataloaders , val_dataloaders , test_dataloaders , datamodule , ckpt_path , ) def _active_fit_impl ( self , model : BaseQueryStrategy , train_dataloaders : Optional [ Union [ TRAIN_DATALOADERS , \"pl.LightningDataModule\" ]] = None , val_dataloaders : Optional [ EVAL_DATALOADERS ] = None , test_dataloaders : Optional [ EVAL_DATALOADERS ] = None , datamodule : Optional [ \"pl.LightningDataModule\" ] = None , ckpt_path : Optional [ str ] = None , ) -> None : \"\"\" Check the inputs \"\"\" # check inputs if not isinstance ( model , BaseQueryStrategy ): raise MisconfigurationException ( f \"model must be a `BaseQueryStrategy` not { type ( model ) . __class__ . __name__ } .\" ) # if a datamodule comes in as the second arg, then fix it for the user if isinstance ( train_dataloaders , pl . LightningDataModule ): datamodule = train_dataloaders train_dataloaders = None is_dataloaders = train_dataloaders is not None or val_dataloaders is not None or test_dataloaders is not None is_datamodule = datamodule is not None # if you supply a datamodule you can't supply train_dataloader or val_dataloaders if is_dataloaders and is_datamodule : raise MisconfigurationException ( \"You cannot pass `train_dataloader` or `val_dataloaders` or \" , \"`test_dataloaders` to `trainer.active_fit(datamodule=...)`\" , ) # cast to ActiveDataModule elif is_dataloaders or ( is_datamodule and not isinstance ( datamodule , ActiveDataModule )): datamodule = ActiveDataModule ( train_dataloader = train_dataloaders , val_dataloaders = val_dataloaders , test_dataloaders = test_dataloaders , datamodule = datamodule , ) # check if can run testing if self . test_after_labelling and getattr ( datamodule , \"test_dataloader\" , None ) is None : raise MisconfigurationException ( \"You specified `test_after_labelling=True` but no test_dataloader was provided.\" ) \"\"\" Set states \"\"\" # patch progress bar and add pool-related hooks _old_callbacks = self . callbacks self . callbacks = patch_callbacks ( self . callbacks ) # set states as in the original `_fit_impl` self . active_fitting = True # TODO: some of these are duplicated in the `reset_{fitting, test}` methods in `ActiveLearningLoop` pl . Trainer . _log_api_event ( \"fit\" ) logger . info ( f \" { self . __class__ . __name__ } : trainer active_fit stage\" ) self . state . fn = TrainerFn . FITTING self . state . status = TrainerStatus . RUNNING self . training = True self . _last_train_dl_reload_epoch = float ( \"-inf\" ) self . _last_val_dl_reload_epoch = float ( \"-inf\" ) self . _last_test_dl_reload_epoch = float ( \"-inf\" ) # links data to the trainer self . _data_connector . attach_data ( model , datamodule = datamodule ) # TODO: ckpt_path only in v2.0 ckpt_path = ckpt_path or self . resume_from_checkpoint self . _ckpt_path = self . __set_ckpt_path ( ckpt_path , model_provided = True , model_connected = self . lightning_module is not None ) \"\"\" Run active fit loop \"\"\" # NOTE: pass the underlying `LightningModule` to `_run` so that it finds # the `training_step` method etc results = self . _run ( model . model , ckpt_path = self . ckpt_path ) \"\"\" Reset states \"\"\" assert self . state . stopped self . training = False self . active_fitting = False # reset original callbacks self . callbacks = _old_callbacks return results def reset_pool_dataloader ( self , model : Optional [ \"pl.LightningModule\" ] = None ) -> None : \"\"\"Resets the pool dataloader and determines the number of batches. This method is exactly the same as `trainer.reset_test_dataloader`. Args: model: The ``LightningModule`` if called outside of the trainer scope. \"\"\" # source = self._data_connector._pool_dataloader_source pl_module = self . lightning_module or model # has_step = is_overridden(\"pool_step\", pl_module, BaseQueryStrategy) enable_pool = self . limit_pool_batches > 0 # if has_step and enable_pool: if enable_pool : self . num_pool_batches , self . pool_dataloaders = self . _data_connector . _reset_eval_dataloader ( PoolRunningStage . POOL , model = pl_module ) \"\"\" Extend methods that need to be called in the `__init__` \"\"\" def _extend_init_debugging_flags ( self ) -> None : \"\"\"This method extends the original `trainer._init_debugging_flags` method.\"\"\" if self . fast_dev_run : num_batches = int ( self . fast_dev_run ) self . limit_pool_batches = num_batches self . fit_loop . max_steps = num_batches self . fit_loop . max_epochs = 1 self . limit_pool_batches = _determine_batch_limits ( self . limit_pool_batches , \"limit_pool_batches\" ) def _extend_setup_on_init ( self ) -> None : \"\"\"This method extends the original `trainer._setup_on_init` method.\"\"\" self . num_pool_batches = [] self . pool_dataloaders = None \"\"\" Patch `_run_train` implementation \"\"\" def _run_train ( self ) -> List [ LabellingIterOutputs ]: \"\"\"Method that depending on `self.active_fitting` selects which loop to run. If `self.active_fitting is False` it runs the usual `fit_loop`, otherwise runs the `active_learning_loop`. \"\"\" if not self . active_fitting : # run normal fit_loop return super () . _run_train () # NOTE: this exactly mimics what they do in `super()._run_train()` self . _pre_training_routine () with isolate_rng (): self . _run_sanity_check () # enable train mode self . model . train () torch . set_grad_enabled ( True ) self . active_learning_loop . trainer = self with torch . autograd . set_detect_anomaly ( self . _detect_anomaly ): results = self . active_learning_loop . run () return results \"\"\" Dispatch properties calls to the right `FitLoop` depending on whether we are `active_fitting` or simply training \"\"\" @property def global_step ( self ) -> int : \"\"\"The number of optimizer steps taken (does not reset each epoch). This includes multiple optimizers and TBPTT steps (if enabled). \"\"\" if self . active_fitting : return self . active_learning_loop . fit_loop . epoch_loop . global_step return self . fit_loop . epoch_loop . global_step @property def current_epoch ( self ) -> int : \"\"\"The current epoch, updated after the epoch end hooks are run.\"\"\" if self . active_fitting : return self . active_learning_loop . fit_loop . epoch_progress . current . completed return self . fit_loop . epoch_progress . current . completed @property def max_epochs ( self ) -> int : if self . active_fitting : return self . active_learning_loop . fit_loop . max_epochs return self . fit_loop . max_epochs @property def min_epochs ( self ) -> int : if self . active_fitting : return self . active_learning_loop . fit_loop . min_epochs return self . fit_loop . min_epochs @property def max_steps ( self ) -> int : if self . active_fitting : return self . active_learning_loop . fit_loop . max_steps return self . fit_loop . max_steps @property def min_steps ( self ) -> Optional [ int ]: if self . active_fitting : return self . active_learning_loop . fit_loop . min_steps return self . fit_loop . min_steps @property def is_last_batch ( self ) -> bool : \"\"\"Whether trainer is executing the last batch.\"\"\" if self . active_fitting : return self . active_learning_loop . fit_loop . epoch_loop . batch_progress . is_last_batch return self . fit_loop . epoch_loop . batch_progress . is_last_batch @property def _evaluation_loop ( self ) -> EvaluationLoop : if self . state . fn in ( TrainerFn . FITTING , TrainerFn . TUNING ): return ( self . fit_loop . epoch_loop . val_loop if not self . active_fitting else self . active_learning_loop . fit_loop . epoch_loop . val_loop ) if self . state . fn == TrainerFn . VALIDATING : return ( self . validate_loop if not self . active_fitting else self . active_learning_loop . fit_loop . epoch_loop . val_loop ) if self . state . fn == TrainerFn . TESTING : return self . test_loop if not self . active_fitting else self . active_learning_loop . test_loop raise RuntimeError ( \"The `Trainer._evaluation_loop` property isn't defined. Accessed outside of scope\" ) @property def _active_loop ( self ) -> Optional [ Union [ FitLoop , EvaluationLoop , PredictionLoop ]]: \"\"\"Returns the currently active loop based on the `Trainer`'s state.\"\"\" if self . training : return self . fit_loop if not self . active_fitting else self . active_learning_loop if self . sanity_checking or self . evaluating : # this resolves the `active_fitting` condition internally return self . _evaluation_loop if self . predicting : return self . predict_loop def set_lightning_module ( self , use_query_strategy : bool = False ) -> None : if use_query_strategy : # self.strategy.model = self.query_strategy self . strategy . connect ( self . query_strategy ) logger . debug ( f \"Using ` { self . lightning_module . __class__ . __name__ } `\" ) else : # self.strategy.model = self.query_strategy.model self . strategy . connect ( self . query_strategy . model ) logger . debug ( f \"Using underlying ` { self . lightning_module . __class__ . __name__ } `\" ) self . strategy . model_to_device () @property def using_query_strategy_as_lightning_module ( self ) -> bool : return isinstance ( self . lightning_module , BaseQueryStrategy )","title":"Trainer"},{"location":"api/trainer/#energizer.trainer.Trainer.current_epoch","text":"The current epoch, updated after the epoch end hooks are run. Source code in energizer/trainer.py 387 388 389 390 391 392 @property def current_epoch ( self ) -> int : \"\"\"The current epoch, updated after the epoch end hooks are run.\"\"\" if self . active_fitting : return self . active_learning_loop . fit_loop . epoch_progress . current . completed return self . fit_loop . epoch_progress . current . completed","title":"current_epoch()"},{"location":"api/trainer/#energizer.trainer.Trainer.global_step","text":"The number of optimizer steps taken (does not reset each epoch). This includes multiple optimizers and TBPTT steps (if enabled). Source code in energizer/trainer.py 377 378 379 380 381 382 383 384 385 @property def global_step ( self ) -> int : \"\"\"The number of optimizer steps taken (does not reset each epoch). This includes multiple optimizers and TBPTT steps (if enabled). \"\"\" if self . active_fitting : return self . active_learning_loop . fit_loop . epoch_loop . global_step return self . fit_loop . epoch_loop . global_step","title":"global_step()"},{"location":"api/trainer/#energizer.trainer.Trainer.is_last_batch","text":"Whether trainer is executing the last batch. Source code in energizer/trainer.py 418 419 420 421 422 423 @property def is_last_batch ( self ) -> bool : \"\"\"Whether trainer is executing the last batch.\"\"\" if self . active_fitting : return self . active_learning_loop . fit_loop . epoch_loop . batch_progress . is_last_batch return self . fit_loop . epoch_loop . batch_progress . is_last_batch","title":"is_last_batch()"},{"location":"api/trainer/#energizer.trainer.Trainer.reset_pool_dataloader","text":"Resets the pool dataloader and determines the number of batches. This method is exactly the same as trainer.reset_test_dataloader . Parameters: Name Type Description Default model Optional [ LightningModule ] The LightningModule if called outside of the trainer scope. None Source code in energizer/trainer.py 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 def reset_pool_dataloader ( self , model : Optional [ \"pl.LightningModule\" ] = None ) -> None : \"\"\"Resets the pool dataloader and determines the number of batches. This method is exactly the same as `trainer.reset_test_dataloader`. Args: model: The ``LightningModule`` if called outside of the trainer scope. \"\"\" # source = self._data_connector._pool_dataloader_source pl_module = self . lightning_module or model # has_step = is_overridden(\"pool_step\", pl_module, BaseQueryStrategy) enable_pool = self . limit_pool_batches > 0 # if has_step and enable_pool: if enable_pool : self . num_pool_batches , self . pool_dataloaders = self . _data_connector . _reset_eval_dataloader ( PoolRunningStage . POOL , model = pl_module )","title":"reset_pool_dataloader()"},{"location":"api/trainer/#energizer.trainer.patch_callbacks","text":"Adds pool -related hooks to callbacks. Source code in energizer/trainer.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def patch_callbacks ( callbacks : List [ Callback ]) -> List [ Callback ]: \"\"\"Adds `pool`-related hooks to callbacks.\"\"\" def add_pool_hooks ( callback : Callback ) -> Callback : hook_names = [ m for m in dir ( CallBackActiveLearningHooks ) if not m . startswith ( \"_\" )] for name in hook_names : if not hasattr ( callback , name ): setattr ( callback , name , getattr ( CallBackActiveLearningHooks , name )) return callback new_callbacks = [] for c in callbacks : if isinstance ( c , ProgressBarBase ): prog_bar = TQDMProgressBarActiveLearning ( process_position = c . process_position , refresh_rate = c . refresh_rate ) prog_bar = add_pool_hooks ( prog_bar ) new_callbacks . append ( prog_bar ) else : new_callbacks . append ( add_pool_hooks ( c )) return new_callbacks","title":"patch_callbacks()"}]}